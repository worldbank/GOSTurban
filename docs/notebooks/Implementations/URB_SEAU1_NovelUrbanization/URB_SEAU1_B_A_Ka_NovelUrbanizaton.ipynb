{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data for urban calculations\n",
    "\n",
    "Test input for Tanzania\n",
    "\n",
    "0. Select focal ADM, buffer by 1km, rasterize as [0, 1]\n",
    "1. Download DEM data from ASTER, mosaick\n",
    "2. Calculate slope of DEM\n",
    "3. Extract water layer from Globcover\n",
    "4. Rasterize building footprints\n",
    "5. Select population layer\n",
    "6. Standardize all rasters to population layer  \n",
    "   a. Set area outside of focal admin to NoData  \n",
    "   b. Set everything to 16bit  \n",
    "   \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wb411133/.conda/envs/ee/lib/python3.9/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.9.1-CAPI-1.14.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METADATA Library: Could not import arcgis libraries\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import shutil\n",
    "import pathlib\n",
    "import datetime\n",
    "import math\n",
    "import rasterio\n",
    "import rasterio.warp\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Import raster helpers\n",
    "sys.path.insert(0, \"/home/wb411133/Code/gostrocks/src\")\n",
    "\n",
    "import GOSTRocks.metadataMisc as meta\n",
    "\n",
    "# Import GOST urban functions\n",
    "sys.path.append(\"../../../src\")\n",
    "\n",
    "# Import local functions\n",
    "import novelUrbanization as nu\n",
    "from novelUrbanization import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_bounds = \"/home/public/Data/GLOBAL/ADMIN/Admin0_Polys.shp\"\n",
    "global_bounds_adm2 = \"/home/public/Data/GLOBAL/ADMIN/Admin2_Polys.shp\"\n",
    "\n",
    "inG = gpd.read_file(global_bounds)\n",
    "inG2 = gpd.read_file(global_bounds_adm2)\n",
    "\n",
    "runSmall = True\n",
    "runLarge = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert EA csv files to geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "in_folder = \"/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/EA_Files/\"\n",
    "ea_files = []\n",
    "for root, dirs, files in os.walk(in_folder):\n",
    "    for x in files:\n",
    "        if (x.endswith(\".csv\")) and (\"URBAN\" not in x):\n",
    "            ea_files.append(os.path.join(root, x))\n",
    "\n",
    "ea_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(ea_files[-1]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def try_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def read_geog(file, lat_column, lon_column, crs=\"epsg:4326\", write_out=True):\n",
    "    print(os.path.basename(file))\n",
    "    out_file = file.replace(\".csv\", \".geojson\")\n",
    "    inD = pd.read_csv(file)\n",
    "\n",
    "    print(inD.shape)\n",
    "    inD[lat_column] = inD[lat_column].apply(try_float)\n",
    "    inD[lon_column] = inD[lon_column].apply(try_float)\n",
    "    inD = inD.loc[~(inD[lat_column].isna() | inD[lon_column].isna())]\n",
    "    print(inD.shape)\n",
    "\n",
    "    inD_geom = inD.apply(\n",
    "        lambda x: Point(float(x[lon_column]), float(x[lat_column])), axis=1\n",
    "    )\n",
    "    inD = gpd.GeoDataFrame(inD, geometry=inD_geom, crs=crs)\n",
    "\n",
    "    if write_out:\n",
    "        inD.to_file(out_file, driver=\"GeoJSON\")\n",
    "    return inD\n",
    "\n",
    "\n",
    "# res = read_geog(ea_files[0], \"latdd_corrected\", \"londd_corrected\")\n",
    "# res = read_geog(ea_files[1], \"lat\", \"lon\")\n",
    "# res = read_geog(ea_files[2], \"latitude\", \"longitude\")\n",
    "# res = read_geog(ea_files[3], \"latitude\", \"longitude\")\n",
    "# res = read_geog(ea_files[4], \"lat_mean\", \"long_mean\")\n",
    "# res = read_geog(ea_files[5], \"latdd_corrected\", \"londd_corrected\")\n",
    "# res = read_geog(ea_files[6], \"latdd_corrected\", \"londd_corrected\")\n",
    "# res = read_geog(ea_files[7], \"lat_modified\",\"lon_modified\")\n",
    "# res = read_geog(ea_files[8], \"lat_corrected\", \"lon_corrected\")\n",
    "# res = read_geog(ea_files[9], \"lat_corrected\", \"lon_corrected\")\n",
    "res = read_geog(ea_files[-1], \"latDD_corrected\", \"lonDD_corrected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run individual counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Process Individual countries\n",
    "iso3 = \"COG\"\n",
    "local_path = \"/home/public/Data/COUNTRY/{country}/WORLDPOP/\".format(country=iso3)\n",
    "constrained_WP_folder = \"/home/public/Data/GLOBAL/Population/RF_SSA_2015-2020\"\n",
    "worldPop_2015 = (\n",
    "    \"/home/public/Data/GLOBAL/Population/WorldPop_PPP_2015/worldPop_2015.vrt\"\n",
    ")\n",
    "global_ghspop = \"/home/public/Data/GLOBAL/Population/GHS/250/GHS_POP_E2015_GLOBE_R2019A_54009_250_V1_0.tif\"\n",
    "c_WP_15 = f\"{constrained_WP_folder}/{iso3}/ppp_{iso3}_const_2015.tif\"\n",
    "c_WP_20 = f\"{constrained_WP_folder}/{iso3}/ppp_{iso3}_const_2020.tif\"\n",
    "custom_pop = \"/home/public/Data/COUNTRY/COG/Population/COG_population_202309271640.tif\"\n",
    "\n",
    "pop_files = [[worldPop_2015, f\"{iso3.lower()}_upo15.tif\"]]\n",
    "pop_files.append([global_ghspop, f\"{iso3.lower()}_gpo.tif\"])\n",
    "pop_files.append([c_WP_15, f\"{iso3.lower()}_cpo15.tif\"])\n",
    "pop_files.append([c_WP_20, f\"{iso3.lower()}_cpo20.tif\"])\n",
    "pop_files.append([custom_pop, f\"{iso3.lower()}_cpo20_WB.tif\"])\n",
    "\n",
    "output_folder = (\n",
    "    \"/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/%s_URBAN_DATA_new_naming\"\n",
    "    % iso3\n",
    ")\n",
    "ea_file = \"/home/public/Data/COUNTRY/COG/Population/ZD_CONGO_CLIP_FIXED.shp\"\n",
    "db_folder = os.path.join(output_folder, \"DB_Results\", \"SentWB\", \"delineations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wb411133/.conda/envs/ee/lib/python3.9/site-packages/geopandas/geodataframe.py:1322: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:50:52\tCOG ***1k Extracting Global Layers\n",
      "11:50:52\tCOG ***1k Downloading and processing elevation\n",
      "11:50:52\tCOG ***1k Standardizing rasters\n",
      "11:50:52\tCOG ***1k Calculating Urban\n",
      "/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/COG_URBAN_DATA_new_naming/FINAL_STANDARD_1KM/cog1k_cpo20.tif\n",
      "/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/COG_URBAN_DATA_new_naming/FINAL_STANDARD_1KM/cog1k_cpo20_WB.tif\n",
      "/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/COG_URBAN_DATA_new_naming/FINAL_STANDARD_1KM/cog1k_upo15.tif\n",
      "/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/COG_URBAN_DATA_new_naming/FINAL_STANDARD_1KM/cog1k_gpo.tif\n",
      "/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/COG_URBAN_DATA_new_naming/FINAL_STANDARD_1KM/cog1k_cpo15.tif\n",
      "11:50:52\tCOG ***1k Calculating Zonal admin2\n",
      "11:50:55\tCOG ***1k Calculating Zonal communes\n",
      "11:53:03\tCOG ***** Extracting Global Layers COG\n",
      "11:53:03\tCOG ***** Downloading and processing elevation COG\n",
      "11:53:03\tCOG ***** Standardizing rasters\n",
      "11:53:03\tCOG ***** Calculating Urban\n",
      "/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/COG_URBAN_DATA_new_naming/FINAL_STANDARD/cog_cpo20.tif\n",
      "/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/COG_URBAN_DATA_new_naming/FINAL_STANDARD/cog_cpo20_WB.tif\n",
      "/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/COG_URBAN_DATA_new_naming/FINAL_STANDARD/cog_upo15.tif\n",
      "/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/COG_URBAN_DATA_new_naming/FINAL_STANDARD/cog_gpo.tif\n",
      "/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/COG_URBAN_DATA_new_naming/FINAL_STANDARD/cog_cpo15.tif\n",
      "11:53:03\tCOG ***** Calculating Zonal admin2\n",
      "11:53:11\tCOG ***** Calculating Zonal communes\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(nu)\n",
    "# Calculate urban definitions\n",
    "nu.calculate_urban(\n",
    "    iso3, inG, inG2, pop_files, ea_file, output_folder, small=runSmall, km=runLarge\n",
    ")\n",
    "pp_urban = nu.calc_pp_urban(\n",
    "    db_folder, \"%s_gpo.tif\" % iso3.lower(), ea_file, output_folder\n",
    ")\n",
    "pd.DataFrame(pp_urban.drop([\"geometry\"], axis=1)).to_csv(\n",
    "    os.path.join(output_folder, f\"{iso3}_DB_UrbanPopulation_admin3.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate Point-based statistics\n",
    "input_file = os.path.join(output_folder, \"HBS_GPS.csv\")\n",
    "pop_tiffs = [\"eth_gpo.tif\", \"eth_upo15.tif\", \"eth_upo16.tif\"]\n",
    "all_tiffs = []\n",
    "base_folder = os.path.join(output_folder, \"FINAL_STANDARD\")\n",
    "base_folder_1km = os.path.join(output_folder, \"FINAL_STANDARD_1KM\")\n",
    "for pFile in pop_tiffs:\n",
    "    all_tiffs.append(os.path.join(base_folder, pFile))\n",
    "    all_tiffs.append(os.path.join(base_folder_1km, pFile.replace(\"eth\", \"eth1k\")))\n",
    "\n",
    "# Read in ETH HH locations, clean\n",
    "inD = pd.read_csv(input_file)\n",
    "inD = inD.loc[~inD[\"latDD_corrected\"].isnull()]\n",
    "inD = inD.loc[~inD[\"lonDD_corrected\"].isnull()]\n",
    "geoms = [\n",
    "    Point(row[\"lonDD_corrected\"], row[\"latDD_corrected\"]) for idx, row in inD.iterrows()\n",
    "]\n",
    "inD = gpd.GeoDataFrame(inD, geometry=geoms, crs={\"init\": \"epsg:4326\"})\n",
    "# Calculate point urbanization for degree of urbanization\n",
    "out_file = os.path.join(output_folder, f\"{iso3}_DoU_Urban.csv\")\n",
    "nu.point_urban_summaries(inD, all_tiffs, out_file)\n",
    "# Calculate point urbanization for PP urban\n",
    "out_file = os.path.join(output_folder, f\"{iso3}_DB_Urban.csv\")\n",
    "in_folder = os.path.join(output_folder, \"ethiopia\")\n",
    "pop_tiffs = [os.path.join(in_folder, x) for x in os.listdir(in_folder)]\n",
    "nu.pp_point_urban_summaries(inD, pop_tiffs, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run zonal stats\n",
    "constrained_WP_folder = \"/home/public/Data/GLOBAL/Population/RF_SSA_2015-2020\"\n",
    "worldPop_2015 = (\n",
    "    \"/home/public/Data/GLOBAL/Population/WorldPop_PPP_2015/worldPop_2015.vrt\"\n",
    ")\n",
    "global_ghspop = \"/home/public/Data/GLOBAL/Population/GHS/250/GHS_POP_E2015_GLOBE_R2019A_54009_250_V1_0.tif\"\n",
    "c_WP_15 = f\"{constrained_WP_folder}/{iso3}/ppp_{iso3}_const_2015.tif\"\n",
    "c_WP_20 = f\"{constrained_WP_folder}/{iso3}/ppp_{iso3}_const_2020.tif\"\n",
    "\n",
    "pop_files = [[worldPop_2015, f\"{iso3.lower()}_upo15.tif\"]]\n",
    "pop_files.append([global_ghspop, f\"{iso3.lower()}_gpo.tif\"])\n",
    "pop_files.append([c_WP_15, f\"{iso3.lower()}_cpo15.tif\"])\n",
    "pop_files.append([c_WP_20, f\"{iso3.lower()}_cpo20.tif\"])\n",
    "\n",
    "nu.run_zonal(iso3, output_folder, inG, pop_files, ea_file, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and copy mapping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "countries = {\n",
    "    \"AGO\": \"angola\",\n",
    "    \"BGD\": \"bangladesh\",\n",
    "    \"EGY\": \"egypt\",\n",
    "    \"ETH\": \"ethiopia\",\n",
    "    \"GHA\": \"ghana\",\n",
    "    \"TZA\": \"tanzania\",\n",
    "    \"VNM\": \"vietnam\",\n",
    "}\n",
    "for iso3 in countries.keys():\n",
    "    out_folder = \"/home/wb411133/data/Projects/MR_Novel_Urbanization/Mapping/URBAN_Data\"\n",
    "    data_folder = (\n",
    "        \"/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/%s_URBAN_DATA_new_naming/\"\n",
    "        % iso3\n",
    "    )\n",
    "    dou_folder = os.path.join(data_folder, \"FINAL_STANDARD\")\n",
    "    db_folder = os.path.join(data_folder, countries[iso3])\n",
    "\n",
    "    dou_urban = os.path.join(dou_folder, f\"{iso3.lower()}_upo15_urban.tif\")\n",
    "    dou_urban_hd = os.path.join(dou_folder, f\"{iso3.lower()}_upo15_urban_hd.tif\")\n",
    "\n",
    "    db_urban_cc = os.path.join(db_folder, f\"{iso3.lower()}_upo15d20b2000_cc.tif\")\n",
    "    db_urban_co = os.path.join(db_folder, f\"{iso3.lower()}_upo15d20b2000_co.tif\")\n",
    "    db_urban_ur = os.path.join(db_folder, f\"{iso3.lower()}_upo15d20b2000_ur.tif\")\n",
    "\n",
    "    for uFile in [dou_urban, dou_urban_hd, db_urban_cc, db_urban_co, db_urban_ur]:\n",
    "        print(f\"{iso3}: {os.path.exists(uFile)}\")\n",
    "        out_file = os.path.join(out_folder, os.path.basename(uFile))\n",
    "        shutil.copy(uFile, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile zonal results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy only the zonal stats with ea defs\n",
    "cur_countries = list(nu.EA_DEFS.keys())\n",
    "\n",
    "in_folder = \"/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/\"\n",
    "out_folder = os.path.join(in_folder, \"URBAN_ZONAL_RESULTS_EAs\")\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "\n",
    "for root, dirs, files in os.walk(in_folder):\n",
    "    if \"URBAN_DATA_new_naming\" in root:\n",
    "        country = os.path.basename(root).split(\"_\")[0]\n",
    "        if country in nu.EA_DEFS.keys():\n",
    "            for f in files:\n",
    "                if (\n",
    "                    (\"EA_PP_URBAN_Updated\" in f)\n",
    "                    | (\"EA_WB_URBAN_\" in f)\n",
    "                    | (\"HH_GPS\" in f)\n",
    "                ):\n",
    "                    fName = pathlib.Path(os.path.join(root, f))\n",
    "                    date = datetime.fromtimestamp(fName.stat().st_mtime)\n",
    "                    if datetime(2021, 6, 1) < date:\n",
    "                        print(f\"{country}: {f} - {date}\")\n",
    "                    else:\n",
    "                        print(f\"***OLD: {country}: {f} - {date}\")\n",
    "                    shutil.copy(os.path.join(root, f), os.path.join(out_folder, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "in_folder = \"/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/\"\n",
    "out_folder = os.path.join(in_folder, \"URBAN_ZONAL_RESULTS\")\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "\n",
    "for root, dirs, files in os.walk(in_folder):\n",
    "    if \"URBAN_DATA_new_naming\" in root:\n",
    "        country = os.path.basename(root).split(\"_\")[0]\n",
    "        if country in nu.EA_DEFS.keys():\n",
    "            for f in files:\n",
    "                if (\n",
    "                    (\"EA_PP_URBAN_Updated\" in f)\n",
    "                    | (\"EA_WB_URBAN_\" in f)\n",
    "                    | (\"HH_GPS\" in f)\n",
    "                ):\n",
    "                    fName = pathlib.Path(os.path.join(root, f))\n",
    "                    date = datetime.fromtimestamp(fName.stat().st_mtime)\n",
    "                    if datetime(2021, 6, 1) < date:\n",
    "                        print(f\"{country}: {f} - {date}\")\n",
    "                    else:\n",
    "                        print(f\"***OLD: {country}: {f} - {date}\")\n",
    "                    shutil.copy(os.path.join(root, f), os.path.join(out_folder, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime(2021, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Delete all zonal stats\n",
    "for root, dirs, files in os.walk(in_folder):\n",
    "    if \"URBAN_DATA_new_naming\" in root:\n",
    "        country = os.path.basename(root).split(\"_\")[0]\n",
    "        if country in nu.EA_DEFS.keys():\n",
    "            for f in files:\n",
    "                if (\"URBAN_COMMUNE_STATS\" in f) | (\"URBAN_ADMIN2\" in f):\n",
    "                    print(f\"{country}: {f}\")\n",
    "                    os.remove(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_metadata = \"/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/LSO_URBAN_DATA_new_naming/METADATA/metadata.xlsx\"\n",
    "dataset_info = pd.read_excel(template_metadata, sheet_name=0)\n",
    "layer_info = pd.read_excel(template_metadata, sheet_name=1, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/{ISO3}_URBAN_DATA_new_naming\"\n",
    "country_name = \"Angola\"\n",
    "iso3 = \"AGO\"\n",
    "in_folder = base_folder.format(ISO3=iso3)\n",
    "out_dir = os.path.join(in_folder, \"metadata\")\n",
    "\n",
    "make_meta = meta.metadata_gost(in_folder, out_dir)\n",
    "layers = make_meta.get_layers()\n",
    "metadata = make_meta.generate_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_info[\"layer_name\"] = [\n",
    "    p.replace(\"lso\", iso3.lower()) for p in layer_info[\"layer_name\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sel_info = layer_info.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"layer_name\",\n",
    "        \"layer_label\",\n",
    "        \"description\",\n",
    "        \"source_name\",\n",
    "        \"source_url\",\n",
    "        \"data_process_summary\",\n",
    "    ],\n",
    "]\n",
    "sel_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_meta = metadata[\"metadata\"]\n",
    "final_meta = final_meta.loc[\n",
    "    :,\n",
    "    ~final_meta.columns.isin(\n",
    "        [\n",
    "            \"layer_label\",\n",
    "            \"description\",\n",
    "            \"source_name\",\n",
    "            \"source_url\",\n",
    "            \"data_process_summary\",\n",
    "        ]\n",
    "    ),\n",
    "]\n",
    "final_meta.merge(sel_info, on=\"layer_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_meta.write_metadata(\n",
    "    os.path.join(out_dir, f\"{iso3}_novel_urbanization_metadata.xlsx\"),\n",
    "    layer_metadata=final_meta,\n",
    "    field_metadata=metadata[\"fields\"],\n",
    "    dataset_id=dataset_info.Definition[0].format(ISO3=iso3, Country=country_name),\n",
    "    dataset_title=dataset_info.Definition[1].format(ISO3=iso3, Country=country_name),\n",
    "    country=dataset_info.Definition[2].format(ISO3=iso3, Country=country_name),\n",
    "    abstract=dataset_info.Definition[3].format(ISO3=iso3, Country=country_name),\n",
    "    purpose=dataset_info.Definition[4].format(ISO3=iso3, Country=country_name),\n",
    "    creation_date=datetime.today().strftime(\"%Y-%m-%d\"),\n",
    "    release_date=datetime.today().strftime(\"%Y-%m-%d\"),\n",
    "    owner=dataset_info.Definition[7].format(ISO3=iso3, Country=country_name),\n",
    "    email=dataset_info.Definition[8].format(ISO3=iso3, Country=country_name),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating zip commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete existing files\n",
    "in_folder = \"/home/wb411133/temp\"\n",
    "for root, dirs, files in os.walk(in_folder):\n",
    "    for d in dirs:\n",
    "        if (d == \"FINAL_STANDARD\") or (d == \"FINAL_STANDARD_1KM\"):\n",
    "            cur_dir = os.path.join(root, d)\n",
    "            print(\n",
    "                \"zip -r {out_file} {infolder}\".format(\n",
    "                    out_file=\"%s_%s.zip\"\n",
    "                    % (cur_dir.split(\"/\")[-2].split(\"_\")[0], cur_dir.split(\"_\")[-1]),\n",
    "                    infolder=os.path.join(\n",
    "                        os.path.basename(os.path.dirname(cur_dir)),\n",
    "                        os.path.basename(cur_dir),\n",
    "                    ),\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is an error in scaling a new population dataset; testing out why\n",
    "pop_raster = \"/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/COG_URBAN_DATA_new_naming/cog_cpo20_WB.tif\"\n",
    "template_raster = \"/home/wb411133/data/Projects/MR_Novel_Urbanization/Data/COG_URBAN_DATA_new_naming/FINAL_STANDARD/cog_gpo.tif\"\n",
    "\n",
    "in_raster = rasterio.open(pop_raster)\n",
    "in_r = in_raster.read()\n",
    "in_r[in_r == in_raster.meta[\"nodata\"]] = 0\n",
    "\n",
    "ghs_R = rasterio.open(template_raster)\n",
    "out_array = np.zeros(ghs_R.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_r[0, 0, 0] == in_raster.meta[\"nodata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_r[0, 0, 0].__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_nodata = type(in_r[0, 0, 0])(in_raster.meta[\"nodata\"])\n",
    "in_r == temp_nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_r == in_raster.meta[\"nodata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_r[in_r < 0] = 0\n",
    "rSample = rasterio.warp.Resampling.bilinear\n",
    "rasterio.warp.reproject(\n",
    "    in_r,\n",
    "    out_array,\n",
    "    src_transform=in_raster.meta[\"transform\"],\n",
    "    dst_transform=ghs_R.meta[\"transform\"],\n",
    "    src_crs=in_raster.crs,\n",
    "    dst_crs=ghs_R.crs,\n",
    "    src_nodata=in_raster.meta[\"nodata\"],\n",
    "    dst_nodata=ghs_R.meta[\"nodata\"],\n",
    "    resampling=rSample,\n",
    ")\n",
    "out_array[out_array == ghs_R.meta[\"nodata\"]] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_array_sum = out_array.sum()\n",
    "original_sum = in_r.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if math.isinf(original_sum):\n",
    "    in_r[in_r < 0] = 0\n",
    "    original_sum = in_r.sum()\n",
    "total_ratio = original_sum / out_array_sum\n",
    "\n",
    "out_array = out_array * total_ratio\n",
    "out_array[out_array < 0] = ghs_R.meta[\"nodata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "749608.9979193077"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_array_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.280417544544301"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'driver': 'GTiff',\n",
       " 'dtype': 'float32',\n",
       " 'nodata': -3.4e+38,\n",
       " 'width': 8939,\n",
       " 'height': 10449,\n",
       " 'count': 1,\n",
       " 'crs': CRS.from_epsg(4326),\n",
       " 'transform': Affine(0.0008333333300145432, 0.0, 11.200416637,\n",
       "        0.0, -0.0008333333299618321, 3.702916853)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_raster.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_r == float(in_raster.meta[\"nodata\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_raster.meta[\"nodata\"].__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Earth Engine",
   "language": "python",
   "name": "ee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
