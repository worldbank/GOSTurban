{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwK54umtCYgr"
   },
   "source": [
    "# **STEP-1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMrArolCC_HU"
   },
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1649162226834,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "q42KpdZ3CHcc"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 35924,
     "status": "ok",
     "timestamp": 1649162263940,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "kD_wjFLZDDqi"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuzVCHyjDYXE"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **Initial file setting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1649162272100,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "E0K1hsfADnHC"
   },
   "outputs": [],
   "source": [
    "f = \"/content/drive/MyDrive/Colab Notebooks/slumML/data/Bambari/Bambari_DA_shape.shp\"  # Input shapefile path\n",
    "outf = \"/content/drive/MyDrive/Colab Notebooks/slumML/data/Bambari/Bambari_DA_morphology.shp\"  # Output shapefile path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1649162274384,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "HQkkty3zDiwu"
   },
   "outputs": [],
   "source": [
    "# Spatial reference setting\n",
    "WGS = \"epsg:4326\"\n",
    "UTM = \"epsg:32629\"\n",
    "\n",
    "# Options for multi-processor process (currently not used)\n",
    "save_thresh = 100000  # save progress every [] rows\n",
    "print_thresh = 10000  # print out calculation process every [] rows for each processor\n",
    "cpuPower = 1 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GupC1EmVEMAY"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **Data treatment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 27127,
     "status": "ok",
     "timestamp": 1649162303460,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "gKQaWpAkERnc"
   },
   "outputs": [],
   "source": [
    "# Prepare the original shape file\n",
    "original = gpd.read_file(f)  # Read ESEI shapefile\n",
    "if original.crs != WGS:\n",
    "    original = original.to_crs(WGS)  # Convert the spatial referenct to WGS if it is not\n",
    "\n",
    "original[\"PID\"] = original.index + 1\n",
    "\n",
    "\n",
    "# Create a deep copy of 'original'\n",
    "fil = original.copy()\n",
    "\n",
    "fil = fil.to_crs(UTM)  # Convert the spatial reference to UTM\n",
    "# Adding attributes to the shapefile: area, geomerty, and PID (unique IDs)\n",
    "fil[\"area\"] = fil.area\n",
    "fil[\"centroid\"] = fil[\"geometry\"].centroid\n",
    "\n",
    "fil = fil.to_crs(WGS)  # Convert back to WGS\n",
    "fil = fil[[\"PID\", \"centroid\", \"area\"]]\n",
    "\n",
    "# short = fil[:50000]# Activate this line and diactivate the below line if you want to test the code with a smaller records.\n",
    "short = fil\n",
    "\n",
    "# Generate KD tree matrix\n",
    "area_dict = dict(zip(list(short.index), list(short[\"area\"])))\n",
    "matrix = list(\n",
    "    zip(short.centroid.apply(lambda x: x.x), short.centroid.apply(lambda x: x.y))\n",
    ")\n",
    "KD_tree = KDTree(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnJRw1cnEncn"
   },
   "source": [
    "**Morphology generation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1649162306665,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "yAP7uTfxEl6W"
   },
   "outputs": [],
   "source": [
    "def Main(passed_dict):\n",
    "    # unpack passed dict into local variables for this thread.\n",
    "    short = passed_dict[\"df\"]\n",
    "    thread_no = passed_dict[\"thread_no\"]\n",
    "    print_thresh = passed_dict[\"print_thresh\"]\n",
    "    save_thresh = passed_dict[\"save_thresh\"]\n",
    "\n",
    "    # set up some counters / timings\n",
    "    t = time.time()\n",
    "    counter = 1\n",
    "\n",
    "    bundle = []\n",
    "\n",
    "    # iterate through each row of the passed DataFrame of housing polygons.\n",
    "    for index, row in short.iterrows():\n",
    "        # identify the x and y coordinates of the house's centroid\n",
    "        y = row.centroid.y\n",
    "        x = row.centroid.x\n",
    "\n",
    "        # Query the KD tree for the first 26 objects (1 will be the house itself.)\n",
    "        # this returns a dataframe of the nearest 26 objects, their distances, and their indices.\n",
    "        distances, indices = KD_tree.query([(x, y)], k=26)\n",
    "\n",
    "        # Distance calculations - closest 5\n",
    "        # here, we subset the distances frame for the first 5 neighbours, and calculate summary stats\n",
    "        nearest_5_distances = list(distances[0])[1:6]  # subset / slice\n",
    "        min_5 = min(\n",
    "            nearest_5_distances\n",
    "        )  # closest neighbour of the 5 closest (min distance to another building)\n",
    "        max_5 = max(\n",
    "            nearest_5_distances\n",
    "        )  # furthest neighbour of the 5 closest (min distance to another building)\n",
    "        mean_5 = np.mean(\n",
    "            nearest_5_distances\n",
    "        )  # average distance of centroids of 5 nearest neighbours\n",
    "        median_5 = np.median(\n",
    "            nearest_5_distances\n",
    "        )  # median distance of centroids of 5 nearest neighbours\n",
    "        dist_5_std = np.std(\n",
    "            nearest_5_distances\n",
    "        )  # standard deviation of centroids of 5 nearest neighbours\n",
    "\n",
    "        # Distance calculations - closest 25\n",
    "        # here, we subset the distances frame for the first 25 neighbours, and calculate summary stats\n",
    "        nearest_25_distances = list(distances[0])[1:]\n",
    "        min_25 = min(nearest_25_distances)\n",
    "        max_25 = max(nearest_25_distances)\n",
    "        mean_25 = np.mean(nearest_25_distances)\n",
    "        median_25 = np.median(nearest_25_distances)\n",
    "        dist_25_std = np.std(nearest_5_distances)\n",
    "\n",
    "        # Areal calculations - closest 5\n",
    "        # here, instead of the distances frame we generated via the KD tree, we use the area_dict\n",
    "        # and query it with the indices from the KD tree step\n",
    "        indices_5 = list(indices[0])[1:6]\n",
    "        areas = [area_dict[x] for x in indices_5]\n",
    "        area_5_mean = np.mean(areas)  # mean area of 5 nearest neighbours\n",
    "        area_5_med = np.median(areas)  # median area of 5 nearest neighbours\n",
    "        area_5_stdev = np.std(\n",
    "            areas\n",
    "        )  # standard deviation of area of 5 nearest neighbours\n",
    "\n",
    "        # Areal calculations - closest 25\n",
    "        # repeat above block for closest 25\n",
    "        indices_25 = list(indices[0])[1:]\n",
    "        areas = [area_dict[x] for x in indices_25]\n",
    "        area_25_mean = np.mean(areas)\n",
    "        area_25_med = np.median(areas)\n",
    "        area_25_stdev = np.std(areas)\n",
    "\n",
    "        # Count\n",
    "        # here we turn the process on its head, and identify all objects within certain distance thresholds\n",
    "        count_25m = KD_tree.query_radius([(x, y)], r=25, count_only=True)[\n",
    "            0\n",
    "        ]  # count of buildings in 25m radius\n",
    "        count_50m = KD_tree.query_radius([(x, y)], r=50, count_only=True)[\n",
    "            0\n",
    "        ]  # count of buildings in 50m radius\n",
    "        count_100m = KD_tree.query_radius([(x, y)], r=100, count_only=True)[\n",
    "            0\n",
    "        ]  # count of buildings in 100m radius\n",
    "\n",
    "        # add these stats to a dictionary called 'ans'\n",
    "        ans = {\n",
    "            \"PID\": row.PID,\n",
    "            \"area\": row.area,\n",
    "            \"D5_min\": min_5,\n",
    "            \"D5_max\": max_5,\n",
    "            \"D5_mean\": mean_5,\n",
    "            \"D5_med\": median_5,\n",
    "            \"D5_std\": dist_5_std,\n",
    "            \"A5_mean\": area_5_mean,\n",
    "            \"A5_med\": area_5_med,\n",
    "            \"A5_std\": area_5_stdev,\n",
    "            \"D25_min\": min_25,\n",
    "            \"D25_max\": max_25,\n",
    "            \"D25_mean\": mean_25,\n",
    "            \"D25_med\": median_25,\n",
    "            \"D25_std\": dist_25_std,\n",
    "            \"A25_mean\": area_25_mean,\n",
    "            \"A25_med\": area_25_med,\n",
    "            \"A25_std\": area_25_stdev,\n",
    "            \"Count_25m\": count_25m,\n",
    "            \"Count_50m\": count_50m,\n",
    "            \"Count_100m\": count_100m,\n",
    "        }\n",
    "\n",
    "        bundle.append(ans)\n",
    "\n",
    "        # keep track of progress via this row\n",
    "        if counter % print_thresh == 0:\n",
    "            print(\"%s rows completed at %s\" % (counter, time.ctime()))\n",
    "\n",
    "        \"\"\"\n",
    "        # this functionality saves progress in case the process cannot be finished in one sitting. \n",
    "        # ideally, finish the processing in one sitting. \n",
    "        old = 0\n",
    "        if counter % save_thresh == 0:\n",
    "            saver = pd.DataFrame(bundle)\n",
    "            saver = saver[list(bundle[0].keys())]\n",
    "            if saver.crs != WGS:\n",
    "                saver = saver.to_crs(WGS)\n",
    "            saver = saver.set_index('PID')\n",
    "            saver = saver.set_index('PID')\n",
    "            saver['geometry'] = saver['geometry']\n",
    "            saver = gpd.GeoDataFrame(saver, geometry = 'geometry', crs = WGS)\n",
    "            saver.to_file(os.path.join(pth, 'output_%s_to_%s_thread_%s.shp' % (old, counter, thread_no)), driver = 'ESRI Shapefile')\n",
    "            bundle = []\n",
    "            old = counter\n",
    "        \"\"\"\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    return bundle\n",
    "\n",
    "    print(\"Task completed in %s seconds\" % (time.time() - t))\n",
    "\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1RaBLPyE7Pz"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **Generating building morphology**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44491,
     "status": "ok",
     "timestamp": 1649162355336,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "Auvs_07qFGcw",
    "outputId": "97a8ee7e-8b4d-4230-a13f-ba8ceeda67a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 rows completed at Tue Apr  5 12:38:46 2022\n",
      "20000 rows completed at Tue Apr  5 12:39:00 2022\n",
      "30000 rows completed at Tue Apr  5 12:39:14 2022\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "\n",
    "d = {\n",
    "    \"df\": short,\n",
    "    \"thread_no\": 1,\n",
    "    \"print_thresh\": print_thresh,\n",
    "    \"save_thresh\": save_thresh,\n",
    "}\n",
    "\n",
    "result = Main(d)\n",
    "out_df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAuJYnwEFJS9"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **Post-analytical process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 28874,
     "status": "ok",
     "timestamp": 1649162510022,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "zO0O_WyhFMbY"
   },
   "outputs": [],
   "source": [
    "### Final data output----------------------------------------------------------------\n",
    "original = original.set_index(\"PID\")  # Reset the index of 'original' DF.\n",
    "out_df = out_df.set_index(\"PID\")  # Reset the index of 'out_df'\n",
    "out_df[\"geometry\"] = original[\n",
    "    \"geometry\"\n",
    "]  # Copy the original geometry to the geometry col of 'out_df'\n",
    "out_df = gpd.GeoDataFrame(out_df, geometry=\"geometry\", crs=WGS)\n",
    "out_df.to_file(outf, driver=\"ESRI Shapefile\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPFrE7NgvLX3bil/AKToTSa",
   "collapsed_sections": [],
   "mount_file_id": "1i8cjeXnEH4KWK49QPqea_3tfmAHKbLBO",
   "name": "STEP1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
