{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ng-6APvaCTjz"
   },
   "source": [
    "# **STEP-2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10476,
     "status": "ok",
     "timestamp": 1652081221317,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "BaLbga1UeeID",
    "outputId": "ddc2866d-511e-4f78-ad37-5e91d75a9e05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lY0lVSWE86u"
   },
   "source": [
    "**OPTIONAL:** Install required modules (geopandas, pyproj, h2o) if not yet installed.\n",
    "Create 'modules' directory under 'Colab\\ Notebooks' (or specify a directory you like).\n",
    "\n",
    "https://ggcs.io/2020/06/22/google-colab-pip-install/ (Japanese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5sJCm-ZyD_a3"
   },
   "outputs": [],
   "source": [
    "!pip install --target /content/drive/MyDrive/Colab\\ Notebooks/modules geopandas pyproj h2o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPbQEJvZIXas"
   },
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 209,
     "status": "ok",
     "timestamp": 1652081234256,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "noTOcSfdEmLJ"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 53111,
     "status": "ok",
     "timestamp": 1652081288302,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "R_-1zemWBe3V"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "import pyproj\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from h2o.frame import H2OFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpsPI01sCAU_"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Initial file setting\n",
    "Do not forget to mount your GoogleDrive! All necessary files need to be uploaded in directories on your GoogleDrive. You can easily mount your GoogleDrive from the left pane, click the folder icon and select mount drive. Also see: https://colab.research.google.com/notebooks/io.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1652081337297,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "x0Rl8cyiTiDT"
   },
   "outputs": [],
   "source": [
    "pth = \"/content/drive/MyDrive/Colab Notebooks/slumML/data/Yaounde/\"  # Directory to save model, ouputs\n",
    "building_file = \"/content/drive/MyDrive/Colab Notebooks/slumML/data/Yaounde/Yaounde_DA_morphology.shp\"  # Specify the processed building footprint data\n",
    "sample_file = \"/content/drive/MyDrive/Colab Notebooks/slumML/data/Yaounde/Yaounde_sample_data.shp\"  # Specify the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 128736,
     "status": "ok",
     "timestamp": 1652081468022,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "d5A4MLXLB7Ad"
   },
   "outputs": [],
   "source": [
    "# Read a Building Footprint layer processed at STEP-1\n",
    "proj_4326 = pyproj.Proj(4326)\n",
    "\n",
    "building_df = gpd.read_file(building_file)\n",
    "building_df = building_df.to_crs(4326)\n",
    "\n",
    "# Read a Sample Area layer\n",
    "sample_area = gpd.read_file(sample_file)\n",
    "sample_area = sample_area.to_crs(4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DS0NcJ-VSCbj"
   },
   "source": [
    "Here, adjust your prediction and response variables.\n",
    "Modify the code below to satisfy your needs.Current setting is very basic: Apply all variables in the building_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1652081494317,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "S9tRIOowjSIH"
   },
   "outputs": [],
   "source": [
    "# Urban classes to be used in the sample layer and for classification\n",
    "# Assign unique integer for each class by yourself here.\n",
    "# class_map = {'High Income':1,'Middle income':2,'Industrial':5, 'Informal':3, 'Commercial':4}\n",
    "# class_map = {'High income':1,'Middle income':2,'Informal':3, 'Commercial':4}\n",
    "# class_map = {'commercial':1,'industrial':2,'ins_admin':3, 'res':4, 'res_detached':5, 'slum':6}#Nairobi\n",
    "# class_map = {'Commercial zone':1,'Formal':2,'Informal':3, 'middle income':4}#Bangui\n",
    "# class_map = {'High Income':1,'Middle Income':2,'Low Income':3, 'Slum':4, 'Com Admin':5, 'Industrial':6}#Libreville, Brazzaville, & PointeNoire\n",
    "# class_map = {'commercial':1,'informal':2,'mid/low income':3}#Bambari\n",
    "class_map = {\n",
    "    \"Administrative\": 0,\n",
    "    \"Bidonville\": 1,\n",
    "    \"Commercial\": 2,\n",
    "    \"High income\": 3,\n",
    "    \"Industrial\": 4,\n",
    "    \"Middle/Low income\": 5,\n",
    "}  # Douala, Yaounde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 192,
     "status": "ok",
     "timestamp": 1652081504301,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "Tn-1WOeK0dY8"
   },
   "outputs": [],
   "source": [
    "# Here, adjust your prediction and response variables. Modify the code below to satisfy your needs.\n",
    "# Current setting is very basic: Apply all variables in the building_df.\n",
    "col = building_df.columns\n",
    "predictors = list(col[1:22])\n",
    "response = \"type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zGujLDrGMWJ"
   },
   "outputs": [],
   "source": [
    "### OPTIONAL ###\n",
    "# The col defining the urban space type should have 'type' name. So, if not, rename it here.\n",
    "sample_area = sample_area.rename(columns={\"class\": \"type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 91882,
     "status": "ok",
     "timestamp": 1652081629044,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "HcEecyh9R3DP"
   },
   "outputs": [],
   "source": [
    "### Generate a training data by intersecting 'building_df' and 'sample_area'\n",
    "# Set urban class default as 'unknown'\n",
    "\n",
    "source_df = building_df.copy()\n",
    "\n",
    "source_df[\"type\"] = \"unknown\"\n",
    "\n",
    "# Create an empty DF for append\n",
    "training_data = pd.DataFrame()\n",
    "\n",
    "# 'training_data' is now our official 'training data' for the ML model.\n",
    "for index, row in sample_area.iterrows():\n",
    "    x = row.geometry\n",
    "    y = row.type\n",
    "\n",
    "    df_temp = source_df[source_df.intersects(x)].copy()\n",
    "    df_temp[\"type\"] = y\n",
    "\n",
    "    training_data = training_data.append(df_temp)\n",
    "\n",
    "training_data[\"type\"] = training_data[\"type\"].map(class_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82ku5ND2SOWr"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# **h2o Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvN08ZHeTSmd"
   },
   "source": [
    "Initialize h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "executionInfo": {
     "elapsed": 15589,
     "status": "ok",
     "timestamp": 1652081655900,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "ekizevAsSxFQ",
    "outputId": "79207c6e-d35a-4b71-bd9e-e42de8ed0218"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"11.0.15\" 2022-04-19; OpenJDK Runtime Environment (build 11.0.15+10-Ubuntu-0ubuntu0.18.04.1); OpenJDK 64-Bit Server VM (build 11.0.15+10-Ubuntu-0ubuntu0.18.04.1, mixed mode, sharing)\n",
      "  Starting server from /content/drive/MyDrive/Colab Notebooks/modules/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmps3fyhcp5\n",
      "  JVM stdout: /tmp/tmps3fyhcp5/h2o_unknownUser_started_from_python.out\n",
      "  JVM stderr: /tmp/tmps3fyhcp5/h2o_unknownUser_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n",
      "Warning: Your H2O cluster version is too old (3 months and 13 days)!Please download and install the latest version from http://h2o.ai/download/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>04 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.36.0.2</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>3 months and 13 days !!!</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_unknownUser_b0cajz</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.172 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, Infogram, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.13 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         04 secs\n",
       "H2O_cluster_timezone:       Etc/UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.36.0.2\n",
       "H2O_cluster_version_age:    3 months and 13 days !!!\n",
       "H2O_cluster_name:           H2O_from_python_unknownUser_b0cajz\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.172 Gb\n",
       "H2O_cluster_total_cores:    2\n",
       "H2O_cluster_allowed_cores:  2\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, Infogram, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.13 final\n",
       "--------------------------  ----------------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICa4GXDWTY1o"
   },
   "source": [
    "Data prep for the h2o pipeline, autoML model selection.\n",
    "The best-performed model will be saved in the directory specified by 'pth.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2286285,
     "status": "ok",
     "timestamp": 1652083949200,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "74Z9NlvxSUBm",
    "outputId": "ebb4410d-e186-4f06-a6d8-38bb4a581833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n",
      "** Model validation with 'valid' hf **\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "\n",
      "ModelMetricsMultinomialGLM: stackedensemble\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.01759988910980335\n",
      "RMSE: 0.13266457368040405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the training data to an h2o frame.\n",
    "# NOTE that this process will be inefficien if the original data has many NaNs.\n",
    "hf = H2OFrame(training_data)\n",
    "\n",
    "\n",
    "# This block of code is fairly h2o standard. It trains 20 models on this data,\n",
    "# limiting the runtime to 1 hour. At the end of an hour or training 20 models,\n",
    "# whichever is first, it returns a DataFrame of predictions as preds, ordered by the quality of their predictions.\n",
    "\n",
    "# Split 'hf' into a taraining frame and validation frame.\n",
    "train, valid = hf.split_frame(ratios=[0.8], seed=10)\n",
    "\n",
    "# Identify predictors and response\n",
    "x = predictors\n",
    "y = response\n",
    "\n",
    "## For binary classification, response should be a factor\n",
    "train[y] = train[y].asfactor()\n",
    "valid[y] = valid[y].asfactor()\n",
    "\n",
    "# Run AutoML for 20 base models (limited to 1 hour max runtime by default)\n",
    "aml = H2OAutoML(max_models=20, seed=1)\n",
    "aml.train(x=x, y=y, training_frame=train)\n",
    "\n",
    "# View the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "\n",
    "\n",
    "# Print all rows instead of default (10 rows)\n",
    "lb.head(rows=lb.nrows)\n",
    "\n",
    "print(\"** Model validation with 'valid' hf **\")\n",
    "preds = aml.leader.predict(valid)\n",
    "\n",
    "# Here, we print out the performance of our top performing model.\n",
    "res = aml.leader.model_performance(valid)\n",
    "\n",
    "print(res)\n",
    "\n",
    "# We save the model down to its own save location.\n",
    "model_path = h2o.save_model(model=aml.leader, path=pth, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnH6Xw8QT5ee"
   },
   "source": [
    "### **Supervised ML classification based on the selected model**\n",
    "h2o struggled to generate predictions for more than 100,000 rows at a time.Thus, we split the original DataFrame into 100,000 row chunks, run the predictions on the h2o version of the frame, then send these to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 334981,
     "status": "ok",
     "timestamp": 1652084321443,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "HuWvDj9YT2dY",
    "outputId": "99160640-2aaa-4242-aaf3-db2347dd4db8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Chunk No. 1 ----> row 0–100000\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "Processing Chunk No. 2 ----> row 100000–200000\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "Processing Chunk No. 3 ----> row 200000–300000\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "Processing Chunk No. 4 ----> row 300000–400000\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "Processing Chunk No. 5 ----> row 400000–500000\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "Processing Chunk No. 5 ----> row 500000 till the end\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "max_row_size = 100000\n",
    "\n",
    "chunk_num = int(len(building_df) / max_row_size)\n",
    "chunk_mod = len(building_df) % max_row_size\n",
    "\n",
    "building_df[\"type\"] = \"unknown\"\n",
    "\n",
    "\n",
    "def MLpred(df):\n",
    "    df_input = df[predictors]\n",
    "    # Extract predictor cols only (specified by the 'predictors' LIST)\n",
    "    hf_temp = H2OFrame(df_input)\n",
    "\n",
    "    preds_temp = aml.leader.predict(hf_temp)\n",
    "    pred_df_temp = preds_temp.as_data_frame()\n",
    "\n",
    "    # add 'PID' to 'pred_df_temp' so that it will be merged to the original 'df.'\n",
    "    df.reset_index(inplace=True)\n",
    "    pred_df_temp[\"PID\"] = df.PID\n",
    "\n",
    "    ans = pd.merge(df, pred_df_temp, on=\"PID\")\n",
    "\n",
    "    return ans\n",
    "\n",
    "\n",
    "# Create an empty DF for append\n",
    "prediction_df = pd.DataFrame()\n",
    "\n",
    "# If the total number of building footprints is smaller than 100,000:\n",
    "if len(building_df) < 100000:\n",
    "    # Prediction process here\n",
    "    pred_x = MLpred(building_df)\n",
    "    prediction_df = prediction_df.append(pred_x)\n",
    "\n",
    "else:\n",
    "    for i in range(0, chunk_num):\n",
    "        if i == 0:\n",
    "            print(\"Processing Chunk No. {} ----> row 0–{}\".format(i + 1, max_row_size))\n",
    "            df_temp2 = building_df[0:max_row_size].copy()\n",
    "\n",
    "            # Prediction process here\n",
    "            pred_x = MLpred(df_temp2)\n",
    "\n",
    "            prediction_df = prediction_df.append(pred_x)\n",
    "\n",
    "        else:\n",
    "            start = i * max_row_size\n",
    "            stop = (i * max_row_size) + max_row_size\n",
    "            print(\"Processing Chunk No. {} ----> row {}–{}\".format(i + 1, start, stop))\n",
    "            df_temp2 = building_df[start:stop].copy()\n",
    "\n",
    "            # Prediction process here\n",
    "            pred_x = MLpred(df_temp2)\n",
    "\n",
    "            prediction_df = prediction_df.append(pred_x)\n",
    "\n",
    "    if chunk_mod > 0:\n",
    "        start = chunk_num * max_row_size\n",
    "        print(\"Processing Chunk No. {} ----> row {} till the end\".format(i + 1, start))\n",
    "        df_temp2 = building_df[start:].copy()\n",
    "\n",
    "        # Prediction process here\n",
    "        pred_x = MLpred(df_temp2)\n",
    "\n",
    "        prediction_df = prediction_df.append(pred_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqwpmSsrUIY_"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### **Post-analytical process**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 715775,
     "status": "ok",
     "timestamp": 1652085093365,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "wuP096anUHzu",
    "outputId": "dd0cb167-5cb1-432a-d4b3-468e2590ca74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting reulst to shapefile...\n"
     ]
    }
   ],
   "source": [
    "### Exporting\n",
    "print(\"Exporting reulst to shapefile...\")\n",
    "output_path = pth + \"\\prediction_result.shp\"\n",
    "prediction_df.to_file(output_path, driver=\"ESRI Shapefile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4234,
     "status": "ok",
     "timestamp": 1649758011062,
     "user": {
      "displayName": "立石英吾",
      "userId": "17884307298980796766"
     },
     "user_tz": -540
    },
    "id": "3uhE9cHGH-DI",
    "outputId": "33c0d7ab-5ffc-4e70-a59b-a3c8c2cd005e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: H2ODeprecationWarning: Deprecated, use ``h2o.cluster().shutdown()``.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you sure you want to shutdown the H2O instance running at http://127.0.0.1:54321 (Y/N)? Y\n",
      "H2O session _sid_95c4 closed.\n"
     ]
    }
   ],
   "source": [
    "### Refreshing H2O cluster (if necessary)\n",
    "h2o.shutdown(prompt=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPDUwW/OThJXd73gqgjAayU",
   "collapsed_sections": [],
   "mount_file_id": "1qBfdsFv3exlWCp9Tdm8STEdKPypVpEvO",
   "name": "STEP2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
