{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import rasterio\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "sys.path.insert(0, \"../../../../gostrocks/src\")\n",
    "\n",
    "import GOSTRocks.rasterMisc as rMisc\n",
    "import GOSTRocks.ntlMisc as ntl\n",
    "from GOSTRocks.misc import tPrint\n",
    "\n",
    "sys.path.append(\"../../../src\")\n",
    "\n",
    "import GOST_Urban.UrbanRaster as urban\n",
    "import GOST_Urban.urban_helper as clippy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# read in local important parameters\n",
    "local_json = \"/home/wb411133/Code/urbanParameters.json\"\n",
    "with open(local_json, \"r\") as inJ:\n",
    "    important_vars = json.load(inJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso3 = \"UKR\"\n",
    "output_dir = f\"/home/wb411133/data/Projects/{iso3}_Urbanization\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "population_file = f\"/home/public/Data/GLOBAL/Population/WorldPop_PPP_2020/MOSAIC_ppp_prj_2020/ppp_prj_2020_{iso3}.tif\"\n",
    "admin_bounds = \"/home/public/Data/COUNTRY/UKR/ADMIN/geoBoundaries-UKR-ADM3.geojson\"\n",
    "GHSL_file = \"/home/public/Data/GLOBAL/GHSL/ghsl.vrt\"\n",
    "\n",
    "# Define output files\n",
    "urban_extents_file = os.path.join(output_dir, f\"{iso3}_urban_extents.geojson\")\n",
    "urban_extents_raster_file = os.path.join(output_dir, f\"{iso3}_urban_extents.tif\")\n",
    "urban_extents_hd_file = os.path.join(output_dir, f\"{iso3}_urban_extents_hd.geojson\")\n",
    "urban_extents_hd_raster_file = os.path.join(output_dir, f\"{iso3}_urban_extents_hd.tif\")\n",
    "admin_urban_summary = os.path.join(output_dir, \"adm3_urban_summary.shp\")\n",
    "urban_admin_summary = os.path.join(output_dir, f\"{iso3}_ADM3_urban_summary.csv\")\n",
    "\n",
    "final_folder = os.path.join(output_dir, \"Mapping_Data\")\n",
    "if not os.path.exists(final_folder):\n",
    "    os.makedirs(final_folder)\n",
    "\n",
    "admin_final = os.path.join(final_folder, \"admin_summarized.shp\")\n",
    "urban_final = os.path.join(final_folder, \"urban_summarized.shp\")\n",
    "urban_hd_final = os.path.join(final_folder, \"urban_hd_summarized.shp\")\n",
    "focal_cities = os.path.join(final_folder, \"FOCAL_AOIs.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inAdmin = gpd.read_file(admin_bounds)\n",
    "inP = rasterio.open(population_file)\n",
    "inG = rasterio.open(GHSL_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run urbanization analysis\n",
    "1. Create urban extents  \n",
    "2. Calculate urban population in admin bounds  \n",
    "3. Summarize nighttime lights in extents and admin\n",
    "4. Summarize GHSL in extents and admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create urban extents\n",
    "if not os.path.exists(urban_extents_file):\n",
    "    urban_calculator = urban.urbanGriddedPop(inP)\n",
    "    urban_extents = urban_calculator.calculateUrban(\n",
    "        densVal=3,\n",
    "        totalPopThresh=5000,\n",
    "        smooth=False,\n",
    "        queen=False,\n",
    "        verbose=True,\n",
    "        raster=urban_extents_raster_file,\n",
    "    )\n",
    "    urban_extents_hd = urban_calculator.calculateUrban(\n",
    "        densVal=15,\n",
    "        totalPopThresh=50000,\n",
    "        smooth=True,\n",
    "        queen=False,\n",
    "        verbose=True,\n",
    "        raster=urban_extents_raster_file,\n",
    "    )\n",
    "    urban_extents.to_file(urban_extents_file, driver=\"GeoJSON\")\n",
    "    urban_extents_hd.to_file(urban_extents_hd_file, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Calculate urban population in admin areas\n",
    "pop_worker = clippy.summarize_population(\n",
    "    population_file,\n",
    "    gpd.read_file(admin_bounds),\n",
    "    urban_extents_raster_file,\n",
    "    urban_extents_hd_raster_file,\n",
    ")\n",
    "summarized_urban = pop_worker.calculate_zonal()\n",
    "urban_res = summarized_urban.loc[:, [x for x in summarized_urban.columns if \"SUM\" in x]]\n",
    "urban_res.columns = [\"TOTAL_POP\", \"URBAN_POP\", \"URBAN_HD_POP\"]\n",
    "urban_res[\"shapeID\"] = inAdmin[\"shapeID\"]\n",
    "urban_res[\"shapeName\"] = inAdmin[\"shapeName\"]\n",
    "urban_res.to_csv(urban_admin_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Summarize nighttime lights in admin bounds and urban extents\n",
    "ntl_files = ntl.find_monthly_ntl()\n",
    "\n",
    "urbanD = gpd.read_file(urban_extents_file)\n",
    "urbanHD = gpd.read_file(urban_extents_hd_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viirs_folder = os.path.join(output_dir, \"NTL_ZONAL_RES\")\n",
    "if not os.path.exists(viirs_folder):\n",
    "    os.makedirs(viirs_folder)\n",
    "\n",
    "for ntl_file in ntl_files:\n",
    "    inR = rasterio.open(ntl_file)\n",
    "    name = os.path.basename(ntl_file).split(\"_\")[3]\n",
    "    tPrint(\"Processing %s\" % name)\n",
    "    urban_res_file = os.path.join(viirs_folder, f\"URBAN_{name}.csv\")\n",
    "    urban_hd_res_file = os.path.join(viirs_folder, f\"HD_URBAN_{name}.csv\")\n",
    "    admin_res_file = os.path.join(viirs_folder, f\"ADMIN_{name}.csv\")\n",
    "\n",
    "    # Urban Summary\n",
    "    if not os.path.exists(urban_res_file):\n",
    "        urban_res = rMisc.zonalStats(urbanD, inR, minVal=0.1)\n",
    "        col_names = [f\"URBAN_{name}_{x}\" for x in [\"SUM\", \"MIN\", \"MAX\", \"MEAN\"]]\n",
    "        urban_df = pd.DataFrame(urban_res, columns=col_names)\n",
    "        urban_df.to_csv(urban_res_file)\n",
    "    # HD Urban Summary\n",
    "    if not os.path.exists(urban_hd_res_file):\n",
    "        hd_urban_res = rMisc.zonalStats(urbanHD, inR, minVal=0.1)\n",
    "        col_names = [f\"HD_URBAN_{name}_{x}\" for x in [\"SUM\", \"MIN\", \"MAX\", \"MEAN\"]]\n",
    "        hd_urban_df = pd.DataFrame(hd_urban_res, columns=col_names)\n",
    "        hd_urban_df.to_csv(urban_hd_res_file)\n",
    "    # admin Summary\n",
    "    if not os.path.exists(admin_res_file):\n",
    "        admin_res = rMisc.zonalStats(inAdmin, inR, minVal=0.1)\n",
    "        col_names = [f\"ADM_URBAN_{name}_{x}\" for x in [\"SUM\", \"MIN\", \"MAX\", \"MEAN\"]]\n",
    "        admin_df = pd.DataFrame(admin_res, columns=col_names)\n",
    "        admin_df.to_csv(admin_res_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile VIIRS results\n",
    "urb_files = [x for x in os.listdir(viirs_folder) if x.startswith(\"URBAN\")]\n",
    "for x in urb_files:\n",
    "    tempD = pd.read_csv(os.path.join(viirs_folder, x), index_col=0)\n",
    "    urbanD[x[:-4]] = tempD.iloc[:, 0]\n",
    "\n",
    "hd_urb_files = [x for x in os.listdir(viirs_folder) if x.startswith(\"HD_URBAN\")]\n",
    "for x in hd_urb_files:\n",
    "    tempD = pd.read_csv(os.path.join(viirs_folder, x), index_col=0)\n",
    "    urbanHD[x[:-4]] = tempD.iloc[:, 0]\n",
    "\n",
    "admin_urb_files = [x for x in os.listdir(viirs_folder) if x.startswith(\"ADMIN\")]\n",
    "for x in admin_urb_files:\n",
    "    tempD = pd.read_csv(os.path.join(viirs_folder, x), index_col=0)\n",
    "    inAdmin[x[:-4]] = tempD.iloc[:, 0]\n",
    "\n",
    "urbanD.to_csv(urban_viirs_summary)\n",
    "urbanHD.to_csv(urban_hd_viirs_summary)\n",
    "inAdmin.to_csv(admin_viirs_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Summarize GHSL in extents and admin\n",
    "ghsl_cols = [f\"c_{x}\" for x in [1, 2, 3, 4, 5, 6]]\n",
    "admin_ghsl_summary = os.path.join(output_dir, \"admin_GHSL_summary.csv\")\n",
    "urban_ghsl_summary = os.path.join(output_dir, \"urban_GHSL_summary.csv\")\n",
    "urbanHD_ghsl_summary = os.path.join(output_dir, \"urbanhd_GHSL_summary.csv\")\n",
    "\n",
    "if not os.path.exists(admin_ghsl_summary):\n",
    "    res = rMisc.zonalStats(\n",
    "        inAdmin, inG, rastType=\"C\", unqVals=[1, 2, 3, 4, 5, 6], reProj=True\n",
    "    )\n",
    "    res = pd.DataFrame(res, columns=ghsl_cols)\n",
    "    res[\"gID\"] = inAdmin[\"shapeID\"]\n",
    "    res.to_csv(admin_ghsl_summary)\n",
    "\n",
    "if not os.path.exists(urban_ghsl_summary):\n",
    "    res = rMisc.zonalStats(\n",
    "        urbanD, inG, rastType=\"C\", unqVals=[1, 2, 3, 4, 5, 6], reProj=True\n",
    "    )\n",
    "    res = pd.DataFrame(res, columns=ghsl_cols)\n",
    "    res[\"gID\"] = urbanD[\"ID\"]\n",
    "    res.to_csv(urban_ghsl_summary)\n",
    "\n",
    "if not os.path.exists(urbanHD_ghsl_summary):\n",
    "    res = rMisc.zonalStats(\n",
    "        urbanHD, inG, rastType=\"C\", unqVals=[1, 2, 3, 4, 5, 6], reProj=True\n",
    "    )\n",
    "    res = pd.DataFrame(res, columns=ghsl_cols)\n",
    "    res[\"gID\"] = urbanHD[\"ID\"]\n",
    "    res.to_csv(urbanHD_ghsl_summary)\n",
    "\n",
    "for ghsl_file in [admin_ghsl_summary, urban_ghsl_summary, urbanHD_ghsl_summary]:\n",
    "    adm_ghsl = pd.read_csv(ghsl_file, index_col=0)\n",
    "    adm_ghsl[\"b2014\"] = adm_ghsl.apply(\n",
    "        lambda x: x[\"c_3\"] + x[\"c_4\"] + x[\"c_5\"] + x[\"c_6\"], axis=1\n",
    "    )\n",
    "    adm_ghsl[\"b2000\"] = adm_ghsl.apply(lambda x: x[\"c_4\"] + x[\"c_5\"] + x[\"c_6\"], axis=1)\n",
    "    adm_ghsl[\"b1990\"] = adm_ghsl.apply(lambda x: x[\"c_5\"] + x[\"c_6\"], axis=1)\n",
    "\n",
    "    def get_built(x):\n",
    "        cur_built = x[\"b2014\"]\n",
    "        base_built = x[\"b1990\"]\n",
    "        if base_built == 0:\n",
    "            base_built = x[\"b2000\"]\n",
    "        try:\n",
    "            return (cur_built - base_built) / base_built\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    adm_ghsl[\"g_14_90\"] = adm_ghsl.apply(get_built, axis=1)\n",
    "    adm_ghsl.to_csv(ghsl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile all results for admin divisions and urban extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile data\n",
    "# [shapefile, population_summary, viirs_summary, ghsl_summary, out_file]\n",
    "for cur_def in [\n",
    "    [\n",
    "        admin_bounds,\n",
    "        urban_admin_summary,\n",
    "        admin_viirs_summary,\n",
    "        admin_ghsl_summary,\n",
    "        admin_final,\n",
    "    ],\n",
    "    [urban_extents_file, \"\", urban_viirs_summary, urban_ghsl_summary, urban_final],\n",
    "    [\n",
    "        urban_extents_hd_file,\n",
    "        \"\",\n",
    "        urban_hd_viirs_summary,\n",
    "        urbanHD_ghsl_summary,\n",
    "        urban_hd_final,\n",
    "    ],\n",
    "]:\n",
    "    curD = gpd.read_file(cur_def[0])\n",
    "    if cur_def[1] != \"\":\n",
    "        curPop = pd.read_csv(cur_def[1], index_col=0)\n",
    "        curD[\"Pop\"] = curPop[\"TOTAL_POP\"]\n",
    "        curD[\"urbanPop\"] = curPop.apply(\n",
    "            lambda x: x[\"URBAN_POP\"] / x[\"TOTAL_POP\"], axis=1\n",
    "        )\n",
    "        curD[\"urbanPopHD\"] = curPop.apply(\n",
    "            lambda x: x[\"URBAN_HD_POP\"] / x[\"TOTAL_POP\"], axis=1\n",
    "        )\n",
    "    viirsD = pd.read_csv(cur_def[2], index_col=0)\n",
    "    curD[\"NTL2013\"] = viirsD.iloc[:, -8]\n",
    "    curD[\"NTL2020\"] = viirsD.iloc[:, -1]\n",
    "    curD[\"NTL_g\"] = curD.apply(\n",
    "        lambda x: (x[\"NTL2020\"] - x[\"NTL2013\"]) / x[\"NTL2013\"], axis=1\n",
    "    )\n",
    "    ghslD = pd.read_csv(cur_def[3], index_col=0)\n",
    "    curD[\"b2014\"] = ghslD[\"b2014\"]\n",
    "    curD[\"g_14_90\"] = ghslD[\"g_14_90\"]\n",
    "    curD.to_file(cur_def[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.read_file(admin_final).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.read_file(urban_final).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.read_file(urban_hd_final).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract sample data for mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ntl_2013 = os.path.join(final_folder, \"VIIRS_2013.tif\")\n",
    "out_ntl_2014 = os.path.join(final_folder, \"VIIRS_2014.tif\")\n",
    "out_ntl_2020 = os.path.join(final_folder, \"VIIRS_2020.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract nighttime lights for 2013 and 2020\n",
    "ntl_files = ntl.find_monthly_ntl()\n",
    "ntl_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(out_ntl_2013):\n",
    "    rMisc.clipRaster(rasterio.open(ntl_files[1]), inAdmin, out_ntl_2013)\n",
    "\n",
    "if not os.path.exists(out_ntl_2014):\n",
    "    rMisc.clipRaster(rasterio.open(ntl_files[2]), inAdmin, out_ntl_2014)\n",
    "\n",
    "if not os.path.exists(out_ntl_2020):\n",
    "    rMisc.clipRaster(rasterio.open(ntl_files[-1]), inAdmin, out_ntl_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ghsl for the 9 focal cities\n",
    "in_cities = gpd.read_file(focal_cities)\n",
    "in_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "max_cnt = 100\n",
    "for idx, row in in_cities.iterrows():\n",
    "    out_file = os.path.join(final_folder, f\"ghsl_{row['Name']}.tif\")\n",
    "    if not os.path.exists(out_file):\n",
    "        rMisc.clipRaster(\n",
    "            inG,\n",
    "            gpd.GeoDataFrame(\n",
    "                pd.DataFrame(row).transpose(), geometry=\"geometry\", crs=in_cities.crs\n",
    "            ),\n",
    "            out_file,\n",
    "        )\n",
    "    cnt += 1\n",
    "    if cnt >= max_cnt:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worldbank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
