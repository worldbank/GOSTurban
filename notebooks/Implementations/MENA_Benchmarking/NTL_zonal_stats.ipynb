{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking cities in MENA\n",
    "\n",
    "In support of an upcoming Urban flagship report, the MENA team is looking for a series of zonal statistics:\n",
    "\n",
    "- Nighttime Lights, Population, and built-area:  \n",
    "  - Entire FUA  \n",
    "  - Its associated urban center / “core”  \n",
    "  - Associated “periphery”  \n",
    "\n",
    "The unit of analysis is the Functional Urban Areas (FUAs) from the [UCDB Database](https://human-settlement.emergency.copernicus.eu/ghs_stat_ucdb2015mt_r2019a.php). For each FUA, we need to grab the associated urban periphary (lower threshold urban areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "import rasterio\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from shapely.geometry import Point\n",
    "from operator import itemgetter\n",
    "\n",
    "sys.path.append(\"C:/WBG/Work/Code/GOSTrocks/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"C:/WBG/Work/data\"\n",
    "ucdb_file = os.path.join(\n",
    "    data_folder,\n",
    "    \"URBAN\",\n",
    "    \"GHS_STAT_UCDB2015MT_GLOBE_R2019A\",\n",
    "    \"GHS_STAT_UCDB2015MT_GLOBE_R2019A_V1_2.gpkg\",\n",
    ")\n",
    "fua_file = os.path.join(\n",
    "    data_folder, \"URBAN\", \"GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0.gpkg\"\n",
    ")\n",
    "\n",
    "import GOSTrocks.ntlMisc as ntlMisc\n",
    "import GOSTrocks.rasterMisc as rMisc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"s3://wbg-geography01/URBANIZATION/MENA/Extents/\"\n",
    "ucdb_file = \"/home/wb411133/Code/GOSTurban/GHS_STAT_UCDB2015MT_GLOBE_R2019A/GHS_STAT_UCDB2015MT_GLOBE_R2019A_V1_2.gpkg\"\n",
    "fua_file = os.path.join(data_folder, \"GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0.gpkg\")\n",
    "fua_peripheries = os.path.join(data_folder, \"FUA_peripheries.gpkg\")\n",
    "flaring_locations_file = \"https://thedocs.worldbank.org/en/doc/d01b4aebd8a10513c0e341de5e1f652e-0400072024/related/2012-2023-individual-flare-volume-estimates.xlsx?_gl=1*19fhic5*_gcl_au*MzM5MTcxNjUwLjE3MTg2NTk5ODU.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaring_d = pd.read_excel(flaring_locations_file)\n",
    "flaring_d[\"ID\"] = flaring_d.index\n",
    "flaring_geoms = [Point(x) for x in zip(flaring_d[\"Longitude\"], flaring_d[\"Latitude\"])]\n",
    "flaring_d = gpd.GeoDataFrame(flaring_d, geometry=flaring_geoms, crs=4326)\n",
    "all_flares = flaring_d.unary_union\n",
    "flaring_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inU = gpd.read_file(ucdb_file)\n",
    "# If the peripheries exists read them in, if not, create them\n",
    "inF = gpd.read_file(fua_file)\n",
    "m_crs = inF.crs\n",
    "inF = inF.to_crs(inU.crs)\n",
    "try:\n",
    "    inP = gpd.read_file(fua_peripheries)\n",
    "except:\n",
    "    fua_peripheries = inF.copy()\n",
    "    for idx, row in inF.iterrows():\n",
    "        # grab the related UCDBs\n",
    "        ucdb_ids = row[\"UC_IDs\"].split(\";\")\n",
    "        ucdb_ids = [int(x) for x in ucdb_ids]\n",
    "        sel_cores = inD.loc[inD[\"ID_HDC_G0\"].isin(ucdb_ids)]\n",
    "        periphery_geom = row[\"geometry\"].difference(sel_cores.unary_union)\n",
    "        fua_peripheries.loc[idx, \"geometry\"] = periphery_geom\n",
    "\n",
    "    fua_peripheries.to_file(\n",
    "        os.path.join(out_folder, \"FUA_peripheries.gpkg\"), driver=\"GPKG\"\n",
    "    )\n",
    "    inP = fua_peripheries\n",
    "inP = inP.to_crs(inU.crs)\n",
    "inP[\"geometry\"] = inP.buffer(0)\n",
    "inU[\"geometry\"] = inU.buffer(0)\n",
    "inF[\"geometry\"] = inF.buffer(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inU['geometry'] = inU.buffer(0)inU['geometry'] = inU.buffer(0)inU['geometry'] = inU.buffer(0)inU['geometry'] = inU.buffer(0)fua_res = \"/home/wb411133/temp/fua_ntl_zonal.csv\"Poison fua_res = \"/home/wb411133/temp/fua_ntl_zonal.csv\"\n",
    "try:\n",
    "    fua_zonal = pd.read_csv(fua_res)\n",
    "except:\n",
    "    fua_zonal = ntlMisc.run_zonal(inF, verbose=True)\n",
    "    fua_zonal.to_csv(fua_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_res = \"/home/wb411133/temp/cores_ntl_zonal.csv\"\n",
    "try:\n",
    "    core_zonal = pd.read_csv(core_res)\n",
    "except:\n",
    "    core_zonal = ntlMisc.run_zonal(inU, verbose=True)\n",
    "    core_zonal.to_csv(core_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" The clipping process produces multi and null geometries, which breaks this process\n",
    "#### TODO: Determine if this is necessary\n",
    "per_res = \"/home/wb411133/temp/periphary_ntl_zonal.csv\"\n",
    "try:\n",
    "    per_zonal = pd.read_csv(per_res)\n",
    "except:\n",
    "    per_zonal = ntlMisc.run_zonal(inP, verbose=True)\n",
    "    per_zonal.to_csv(per_res)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust for flaring\n",
    "\n",
    "Two steps to adjust the nighttime lights data for flaring:\n",
    "1. Mute the nighttime lights data within a buffer zone of each flaring location\n",
    "2. Determine distances between city extents (FUA) and nearest flaring location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Distance calculations\n",
    "\n",
    "\n",
    "def ckdnearest(gdfA, gdfB, gdfB_cols=[\"ID\"]):\n",
    "    A = np.concatenate([np.array(geom.coords) for geom in gdfA.geometry.to_list()])\n",
    "    B = [np.array(geom.coords) for geom in gdfB.geometry.to_list()]\n",
    "    B_ix = tuple(\n",
    "        itertools.chain.from_iterable(\n",
    "            [itertools.repeat(i, x) for i, x in enumerate(list(map(len, B)))]\n",
    "        )\n",
    "    )\n",
    "    B = np.concatenate(B)\n",
    "    ckd_tree = cKDTree(B)\n",
    "    dist, idx = ckd_tree.query(A, k=1)\n",
    "    idx = itemgetter(*idx)(B_ix)\n",
    "    gdf = pd.concat(\n",
    "        [\n",
    "            gdfA,\n",
    "            gdfB.loc[idx, gdfB_cols].reset_index(drop=True),\n",
    "            pd.Series(dist, name=\"dist\"),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    return gdf\n",
    "\n",
    "\n",
    "inF_centroid = inF.copy()\n",
    "inF_centroid[\"geometry\"] = inF_centroid[\"geometry\"].centroid\n",
    "inF_centroid = inF_centroid.to_crs(m_crs)\n",
    "flaring_d = flaring_d.to_crs(m_crs)\n",
    "\n",
    "nearest_calc = ckdnearest(inF_centroid, flaring_d)\n",
    "\n",
    "\"\"\"\n",
    "inF['Inter_Flare'] = 0\n",
    "all_flares = flaring_d.unary_union\n",
    "inF = inF.to_crs(flaring_d.crs)\n",
    "for idx, row in inF.iterrows():\n",
    "    if row['geometry'].intersects(all_flares):\n",
    "        inF.loc[idx, 'Inter_Flare'] = 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Mute nighttime lights data within a mask\n",
    "### Buffer the flare locations by the defined distance\n",
    "buffer_dist = 5000  # (metres)\n",
    "buffered_flare = flaring_d.copy()\n",
    "buffered_flare[\"geometry\"] = buffered_flare[\"geometry\"].apply(\n",
    "    lambda x: x.buffer(buffer_dist)\n",
    ")\n",
    "buffered_flare = buffered_flare.to_crs(4326)\n",
    "\n",
    "### create a mask raster using the buffered flare locations\n",
    "ntl_images = ntlMisc.aws_search_ntl()\n",
    "flare_mask = rMisc.rasterizeDataFrame(\n",
    "    buffered_flare, None, templateRaster=ntl_images[0], nodata=0\n",
    ")\n",
    "flare_mask = (~flare_mask[\"vals\"].astype(bool)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use the mask in the zonal calculation\n",
    "finalF = inF.copy()\n",
    "ntl_image = ntl_images[0]\n",
    "date = os.path.basename(ntl_image).split(\"_\")[2][:6]\n",
    "raw_ntl = rMisc.zonalStats(inF, ntl_image, minVal=0.1, reProj=True)\n",
    "raw_ntl = pd.DataFrame(raw_ntl, columns=[\"SUM\", \"MIN\", \"MAX\", \"MEAN\"])\n",
    "finalF[f\"raw_{date}\"] = raw_ntl[\"SUM\"]\n",
    "\n",
    "ntl_r = rasterio.open(ntl_images[0])\n",
    "ntl_data = ntl_r.read()\n",
    "masked_ntl_data = ntl_data * flare_mask\n",
    "with rMisc.create_rasterio_inmemory(\n",
    "    ntl_r.profile, masked_ntl_data\n",
    ") as masked_ntl_raster:\n",
    "    masked_ntl = rMisc.zonalStats(inF, masked_ntl_raster, minVal=0.1, reProj=True)\n",
    "    masked_ntl = pd.DataFrame(masked_ntl, columns=[\"SUM\", \"MIN\", \"MAX\", \"MEAN\"])\n",
    "finalF[f\"mask_{date}\"] = masked_ntl[\"SUM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalF.to_file(\n",
    "    f\"/home/wb411133/temp/{date}_{buffer_dist}_zonal_ntl.gpkg\", driver=\"GPKG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create mapping and debugging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write flare mask to disk\n",
    "flare_mask_file = os.path.join(\"/home/wb411133/temp\", \"flare_mask.tif\")\n",
    "flare_profile = ntl_r.profile.copy()\n",
    "flare_mask = flare_mask.astype(\"int16\")\n",
    "flare_profile.update(dtype=flare_mask.dtype)\n",
    "\n",
    "with rasterio.open(flare_mask_file, \"w\", **flare_profile) as out_flare:\n",
    "    out_flare.write_band(1, flare_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine raw and masked ntl results with urban extents\n",
    "outF = nearest_calc.copy()\n",
    "outF[\"rawNTL\"] = raw_ntl_df[\"SUM\"]\n",
    "outF[\"maskedNTL\"] = masked_ntl_df[\"SUM\"]\n",
    "outF.to_file(\n",
    "    os.path.join(\"/home/wb411133/temp\", \"urban_extents_ntl_flaring.gpkg\"), driver=\"GPKG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine NTL results\n",
    "We have zonal results for the entire FUA and for the core as monthly results; there is a two step process to create the final results:\n",
    "1. Combine monthly results into annual results  \n",
    "2. Use FUA and cores to generate three stats: FUA SoL, Core SoL, and Periphery SoL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_ntl_annual(curD):\n",
    "    \"\"\"curD is a data frame of ntl zonal results\"\"\"\n",
    "    for yr in range(2012, 2024):\n",
    "        cur_columns = [x for x in curD.columns if f\"ntl_{yr}\" in x]\n",
    "        sel_d = curD.loc[:, cur_columns]\n",
    "        curD[f\"ntl{yr}_SoL\"] = sel_d.sum(axis=1) / len(cur_columns)\n",
    "    return curD\n",
    "\n",
    "\n",
    "out_folder = \"s3://wbg-geography01/URBANIZATION/MENA/ZONAL_RES/NTL/\"\n",
    "combine_ntl_annual(fua_zonal).to_csv(os.path.join(out_folder, \"fua_VIIRS_SoL.csv\"))\n",
    "combine_ntl_annual(core_zonal).to_csv(os.path.join(out_folder, \"core_VIIRS_SoL.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_ntl_annual(core_zonal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempF = inF.loc[inF[\"eFUA_ID\"] == 1281]\n",
    "tempF[\"geometry\"] = tempF[\"geometry\"].iloc[0].buffer(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rMisc.zonalStats(tempF, ntl_images[2], minVal=0.1, reProj=True, allTouched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempF[\"geometry\"].iloc[0].buffer(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Earth Engine",
   "language": "python",
   "name": "ee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
