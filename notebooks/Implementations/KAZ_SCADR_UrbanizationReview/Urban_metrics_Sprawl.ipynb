{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Urban Metrics: Sprawl\n",
    "Normalized difference between the share of areas with population density below the regional average density and the share of areas with population density above the regional average density (Fallah et al., 2011).\n",
    "\n",
    "Sprawl L H = ((L%−H%)+1)*0.5\n",
    "\n",
    "Where L% is the share of metropolitan population living in a grid cell with density below the overall grid cell group median and H% is the share of metropolitan population living in a grid cell with density above the overall grid cell group median. The sprawl measure in Equation (8) is an index that ranges between 0 and 1; values closer to 1 represent greater sprawl.\n",
    "\n",
    "To account for ‘rural clusters’ in metropolitan areas, grid cells with density below 200 persons per square mile are excluded (or 77 per square km)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import mapping\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reference to GOSTNets\n",
    "sys.path.append(r\"C:\\repos\\INFRA_SAP\")\n",
    "from infrasap.urban_metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio import Affine  # or from affine import Affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs are GHS pop and the urban extents\n",
    "Mollweide projection should work good because it is an equal-area projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GHS_pop = r\"C:\\Users\\war-machine\\Documents\\world_bank_work\\UZB_project\\GHS_POP_E2015_GLOBE_R2019A_54009_1K_V1_0\\GHS_POP_E2015_GLOBE_R2019A_54009_1K_V1_0.tif\"\n",
    "# GHS_pop = r\"C:\\Users\\war-machine\\Documents\\world_bank_work\\UZB_project\\clipped_eca_no_russia_1km.tif\"\n",
    "# GHS_pop = r\"C:\\Users\\war-machine\\Documents\\world_bank_work\\UZB_project\\2015_1km_GHS_Pop\\GHS_POP_2015_UZB_merged.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shpName = r\"C:\\Users\\war-machine\\Documents\\world_bank_work\\UZB_project\\metrics_shape_tool\\Final_urban_extent_metrics\\ECA_all_urban_extents_100k_mollweide.shp\"\n",
    "# shpName = r\"C:\\Users\\war-machine\\Documents\\world_bank_work\\UZB_project\\metrics_shape_tool\\russia_urban_extents_merged_mollweide.shp\"\n",
    "# shpName = r\"C:\\repos\\GOST_Urban\\Notebooks\\Implementations\\eca_wo_rus_urban_clusters_ghs_pop_smooth_100k_mollweide2.shp\"\n",
    "# shpName = r\"C:\\Users\\war-machine\\Documents\\world_bank_work\\UZB_project\\metrics_shape_tool\\UZB_only_FUAs_Project_Mollweide.shp\"\n",
    "# shpName = r\"C:\\Users\\war-machine\\Documents\\world_bank_work\\UZB_project\\metrics_shape_tool\\UZB_ghs_built_up_extents_4326\\UZB_only_ghs_built_up_extents_mollweide_geom_fixed_greater_50k.shp\"\n",
    "# shpName = r\"C:\\Users\\war-machine\\Documents\\world_bank_work\\UZB_project\\metrics_shape_tool\\UZB_ghs_built_up_extents_4326\\UZB_ghs_built_up_extents_mollweide_geom_fixed.shp\"\n",
    "# shpName = r\"C:\\Users\\war-machine\\Documents\\world_bank_work\\UZB_project\\metrics_shape_tool\\ECA_wo_rus_urban_extents\\eca_wo_rus_built_up_extents_molleweide.shp\"\n",
    "shpName = r\"C:\\Users\\war-machine\\Documents\\world_bank_work\\UZB_project\\metrics_shape_tool\\all_urban_clusters_5k_up_molleweide.shp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First find overall grid cell group median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode\n",
    "\n",
    "# pop_values = []\n",
    "# For each Shape/FUA:\n",
    "# Select all built-up pixels that are mostly within shape (and exclude pixels less than 77 per square km)\n",
    "# For each pixel:\n",
    "# pop_values.append(pixel value)\n",
    "\n",
    "\n",
    "# cell_group_median = median of pop_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with rasterio.open(GHS_pop) as src:\n",
    "    pixelSizeX, pixelSizeY = src.res\n",
    "    print(pixelSizeX, pixelSizeY)\n",
    "\n",
    "    input_shapes_gpd = gpd.read_file(shpName)\n",
    "\n",
    "    # pop_values = []\n",
    "    pop_values = []\n",
    "    # for entry in input_shapes_gpd.head(2).iterrows():\n",
    "    for entry in input_shapes_gpd.iterrows():\n",
    "        print(entry[0])\n",
    "\n",
    "        # extract the geometry in GeoJSON format\n",
    "        geometry = entry[1][\"geometry\"]  # list of shapely geometries\n",
    "        # geometry = geoms[0] # shapely geometry\n",
    "        # converts to geojson format\n",
    "        geoms = [mapping(geometry)]\n",
    "\n",
    "        # extract the raster values values within the polygon\n",
    "        out_image, out_transform = mask(src, geoms, crop=True, nodata=-9999.0)\n",
    "        data = out_image[0, :, :]\n",
    "\n",
    "        row, col = np.where(data != -9999.0)\n",
    "        val = np.extract(data != -9999.0, data)\n",
    "\n",
    "        # Adding the x,y, and geometry columns is not necessary\n",
    "        T1 = out_transform * Affine.translation(0.5, 0.5)  # reference the pixel centre\n",
    "        # row,column to x,y\n",
    "        rc2xy = lambda r, c: (c, r) * T1\n",
    "\n",
    "        d = gpd.GeoDataFrame({\"col\": col, \"row\": row, \"val\": val})\n",
    "\n",
    "        # coordinate transformation\n",
    "        d[\"x\"] = d.apply(lambda row: rc2xy(row.row, row.col)[0], axis=1)\n",
    "        d[\"y\"] = d.apply(lambda row: rc2xy(row.row, row.col)[1], axis=1)\n",
    "\n",
    "        # geometry\n",
    "        d[\"geometry\"] = d.apply(lambda row: Point(row[\"x\"], row[\"y\"]), axis=1)\n",
    "\n",
    "        # exclude pixels with value less than 77\n",
    "        print(len(d))\n",
    "\n",
    "        # print(d)\n",
    "        print(d.val[d.val > 77].to_list())\n",
    "\n",
    "        print(len(d[d.val > 77]))\n",
    "\n",
    "        # extend values to pop_values\n",
    "        pop_values.extend(d.val[d.val > 77].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "UZB_pop_median = statistics.median(pop_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UZB_pop_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second calculate the Sprawl metric for each shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode\n",
    "\n",
    "# for each Shape/FUA:\n",
    "# pixel_count_below_median = 0\n",
    "# pixel_count_above_median = 0\n",
    "\n",
    "# Select all built-up pixels that are mostly within shape (and exclude pixels less than 77 per square km)\n",
    "# calculate pixel_share_below_median and pixel_share_above_median\n",
    "\n",
    "# Sprawl = ((L%−H%)+1)*0.5\n",
    "# Sprawl = ((pixel_share_below_median-pixel_share_above_median)+1)*.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with rasterio.open(GHS_pop) as src:\n",
    "    pixelSizeX, pixelSizeY = src.res\n",
    "    print(pixelSizeX, pixelSizeY)\n",
    "\n",
    "    input_shapes_gpd = gpd.read_file(shpName)\n",
    "\n",
    "    # pixel_count_below_median = 0\n",
    "    pixel_count_below_median = 0\n",
    "    # pixel_count_above_median = 0\n",
    "    pixel_count_above_median = 0\n",
    "\n",
    "    # for entry in input_shapes_gpd.head(3).iterrows():\n",
    "    for entry in input_shapes_gpd.iterrows():\n",
    "        print(entry[0])\n",
    "\n",
    "        # extract the geometry in GeoJSON format\n",
    "        geometry = entry[1][\"geometry\"]  # list of shapely geometries\n",
    "        # geometry = geoms[0] # shapely geometry\n",
    "        geoms = [mapping(geometry)]\n",
    "\n",
    "        # extract the raster values values within the polygon\n",
    "        out_image, out_transform = mask(src, geoms, crop=True, nodata=-9999.0)\n",
    "        data = out_image[0, :, :]\n",
    "\n",
    "        row, col = np.where(data != -9999.0)\n",
    "        val = np.extract(data != -9999.0, data)\n",
    "\n",
    "        d = gpd.GeoDataFrame({\"col\": col, \"row\": row, \"val\": val})\n",
    "\n",
    "        # exclude pixels with value less than 77\n",
    "        d = d[d.val > 77]\n",
    "        d_count = len(d)\n",
    "        # print(f\"d_count is {d_count}\")\n",
    "\n",
    "        # print(d.val[d.val < UZB_pop_median])\n",
    "        # print(len(d.val[d.val < UZB_pop_median]))\n",
    "        pixel_share_below_median = len(d.val[d.val < UZB_pop_median]) / d_count\n",
    "        print(f\"pixel_share_below_median is: {pixel_share_below_median}\")\n",
    "\n",
    "        # print(d.val[d.val > UZB_pop_median])\n",
    "        # print(len(d.val[d.val > UZB_pop_median]))\n",
    "        pixel_share_above_median = len(d.val[d.val > UZB_pop_median]) / d_count\n",
    "        print(f\"pixel_share_above_median is: {pixel_share_above_median}\")\n",
    "\n",
    "        # Sprawl = ((L%−H%)+1)*0.5\n",
    "        # Sprawl = ((pixel_count_below_median-pixel_count_above_median)+1)*.5\n",
    "        Sprawl = ((pixel_share_below_median - pixel_share_above_median) + 1) * 0.5\n",
    "        print(f\"Sprawl index is: {Sprawl}\")\n",
    "\n",
    "        # creates a temporary GDF for just the row's shape\n",
    "        temp_gdf = input_shapes_gpd.iloc[[entry[0]]]\n",
    "\n",
    "        # print(\"print temp_gdf\")\n",
    "        # print(temp_gdf)\n",
    "\n",
    "        # Put all metrics in a DataFrame\n",
    "        metrics_scalar = {}\n",
    "        metrics_scalar[\"sprawl_index\"] = [Sprawl]\n",
    "        metrics_df = pd.DataFrame(metrics_scalar)\n",
    "\n",
    "        # print(\"print metrics_scalar\")\n",
    "        # print(metrics_scalar)\n",
    "\n",
    "        # and concatenate it with the row's shape\n",
    "        new_temp_gdf = pd.concat([temp_gdf.reset_index(drop=True), metrics_df], axis=1)\n",
    "\n",
    "        # print(\"print new_temp_gdf\")\n",
    "        # print(new_temp_gdf)\n",
    "        # print(entry[0])\n",
    "        # put the results of each row into a new DataFrame\n",
    "        if entry[0] == 0:\n",
    "            print(\"new_temp_gdf\")\n",
    "            output_new_temp_gdf = new_temp_gdf\n",
    "        else:\n",
    "            output_new_temp_gdf = output_new_temp_gdf.append(\n",
    "                new_temp_gdf, ignore_index=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_new_temp_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the GeoDataFrame unprojected\n",
    "output_new_temp_gdf = output_new_temp_gdf.to_crs(\"epsg:4326\")\n",
    "\n",
    "# output = r\"C:\\Users\\war-machine\\Documents\\world_bank_work\\UZB_project\\metrics_shape_tool\"\n",
    "# output = r\"C:\\Users\\war-machine\\Documents\\world_bank_work\\UZB_project\\metrics_shape_tool\\eca_metrics_results_russia\"\n",
    "# output = r\"C:\\Users\\war-machine\\Documents\\world_bank_work\\UZB_project\\metrics_shape_tool\\eca_urban_metrics_results_wo_rus\"\n",
    "# output = r\"C:\\Users\\war-machine\\Documents\\world_bank_work\\UZB_project\\metrics_shape_tool\\UZB_only_GHS_FUAs_results\"\n",
    "# output = r\"C:\\Users\\war-machine\\Documents\\world_bank_work\\UZB_project\\metrics_shape_tool\\UZB_only_GHS_urban_extents_results\"\n",
    "# output = r\"C:\\Users\\war-machine\\Documents\\world_bank_work\\UZB_project\\metrics_shape_tool\\UZB_only_GHS_urban_extents_results_all\"\n",
    "# output = r\"C:\\Users\\war-machine\\Documents\\world_bank_work\\UZB_project\\metrics_shape_tool\\eca_urban_metrics_results_wo_rus_all\"\n",
    "output = r\"C:\\Users\\war-machine\\Documents\\world_bank_work\\UZB_project\\metrics_shape_tool\\all_urban_extents_results_5k_up\"\n",
    "\n",
    "# save as CSV\n",
    "\n",
    "# output_new_temp_gdf.to_csv(output + r\"\\ECA_all_urban_metrics_100k_sprawl.csv\")\n",
    "# output_new_temp_gdf.to_csv(output + r\"\\UZB_only_urban_metrics_FUAs_sprawl.csv\")\n",
    "# output_new_temp_gdf.to_csv(output + r\"\\UZB_only_urban_metrics_urban_extents_sprawl.csv\")\n",
    "# output_new_temp_gdf.to_csv(output + r\"\\UZB_only_urban_metrics_urban_extents_all_sprawl.csv\")\n",
    "# output_new_temp_gdf.to_csv(output + r\"\\ECA_wo_rus_urban_metrics_urban_extents_all_sprawl.csv\")\n",
    "output_new_temp_gdf.to_csv(output + r\"\\all_urban_metrics_5k_up_sprawl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"total time to process: {time.time()-start_time}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
