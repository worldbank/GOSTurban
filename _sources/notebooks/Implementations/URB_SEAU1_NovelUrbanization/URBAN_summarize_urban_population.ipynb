{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import boto3\n",
    "\n",
    "import rasterio\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from GOSTrocks.misc import tPrint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"wbg-geography01\"\n",
    "prefix = \"URBANIZATION/MR_Novel_Poverty/\"\n",
    "file_ends_with = 'urban_hd.tif'\n",
    "\n",
    "s3client = boto3.client(\"s3\", verify=False)\n",
    "\n",
    "# Loop through the S3 bucket and get all the file keys\n",
    "more_results = True\n",
    "try:\n",
    "    del token  # noqa\n",
    "except Exception:\n",
    "    pass\n",
    "loops = 0\n",
    "\n",
    "all_res = []\n",
    "while more_results:\n",
    "    print(f\"Completed loop: {loops}\")\n",
    "    if loops > 0:\n",
    "        objects = s3client.list_objects_v2(\n",
    "            Bucket=bucket,\n",
    "            ContinuationToken=token,  # noqa\n",
    "            Prefix=prefix,  # noqa\n",
    "        )\n",
    "    else:\n",
    "        objects = s3client.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "    more_results = objects[\"IsTruncated\"]\n",
    "    if more_results:\n",
    "        token = objects[\"NextContinuationToken\"]\n",
    "    loops += 1\n",
    "    for res in objects[\"Contents\"]:\n",
    "        if res['Key'].endswith(file_ends_with):\n",
    "            all_res.append(res['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res = pd.DataFrame(all_res, columns=['Key'])\n",
    "all_res['ISO3'] = all_res['Key'].apply(lambda x: x.split('/')[-1][:3])\n",
    "all_res['pop_layer'] = all_res['Key'].apply(lambda x: x.split('/')[-1].split('_')[1])\n",
    "all_res['file'] = all_res['Key'].apply(lambda x: os.path.basename(x))\n",
    "all_res['res'] = '250'\n",
    "all_res.loc[all_res['file'].str.contains('1k'), 'res'] = '1000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_urban_pop(hd_key, verbose=False):\n",
    "    urban_key = hd_key.replace('urban_hd.tif', 'urban.tif')\n",
    "    pop_key = hd_key.replace('_urban_hd.tif', '.tif')\n",
    "    \n",
    "    # Summarize total population\n",
    "    with rasterio.Env(GDAL_HTTP_UNSAFESSL=\"YES\"):\n",
    "        popR = rasterio.open(f's3://{bucket}/{pop_key}')\n",
    "        popD = popR.read(1)\n",
    "        popD = np.where(popD > 0, popD, 0)\n",
    "        total_pop = popD.sum()\n",
    "\n",
    "        urbanR = rasterio.open(f's3://{bucket}/{urban_key}')\n",
    "        urbanD = urbanR.read(1)\n",
    "        urbanD = np.where(urbanD > 0, 1, 0)\n",
    "        urban_pop = urbanD * popD\n",
    "        urban_pop = urban_pop.sum()\n",
    "\n",
    "        hdR = rasterio.open(f's3://{bucket}/{hd_key}')\n",
    "        hdD = hdR.read(1)\n",
    "        hdD = np.where(hdD > 0, 1, 0)\n",
    "        hd_pop = hdD * popD\n",
    "        hd_pop = hd_pop.sum()\n",
    "    return([total_pop, urban_pop, hd_pop])\n",
    "\n",
    "#xx = calculate_urban_pop(all_res['Key'].iloc[0], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pop_summaries(in_res, sel_res):\n",
    "    focal_set = in_res.loc[(in_res['res'] == sel_res)].copy()\n",
    "    for idx, rows in focal_set.iterrows():\n",
    "        tPrint('Processing: %s' % rows['ISO3'])\n",
    "        try:\n",
    "            total_pop, urban_pop, hd_pop = calculate_urban_pop(rows['Key'])\n",
    "            focal_set.loc[idx, 'total_pop'] = total_pop\n",
    "            focal_set.loc[idx, 'urban_pop'] = urban_pop\n",
    "            focal_set.loc[idx, 'hd_pop'] = hd_pop\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {rows['Key']}\")\n",
    "            print(e)\n",
    "    return(focal_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a single country\n",
    "sel_iso3 = 'cog'\n",
    "sel_country_res = all_res.loc[all_res['ISO3'] == sel_iso3].copy()\n",
    "\n",
    "country_summary = process_pop_summaries(sel_country_res, '1000')\n",
    "country_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_res = '1000'\n",
    "\n",
    "all_res['total_pop'] = 0.\n",
    "all_res['urban_pop'] = 0.\n",
    "all_res['hd_pop'] = 0.\n",
    "\n",
    "\n",
    "focal_set = all_res.loc[(all_res['res'] == sel_res)].copy()\n",
    "for idx, rows in focal_set.iterrows():\n",
    "    tPrint('Processing: %s' % rows['ISO3'])\n",
    "    try:\n",
    "        total_pop, urban_pop, hd_pop = calculate_urban_pop(rows['Key'])\n",
    "        all_res.loc[idx, 'total_pop'] = total_pop\n",
    "        all_res.loc[idx, 'urban_pop'] = urban_pop\n",
    "        all_res.loc[idx, 'hd_pop'] = hd_pop\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {rows['Key']}\")\n",
    "        print(e)\n",
    "\n",
    "all_res.loc[focal_set.index].to_csv(f'C:/Temp/urban_pop_{sel_res}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring population values\n",
    "\n",
    "Each country has a text file evaluating several attributes (listed below), however, I don't see any comparisons between the source data and the re-scaled values:\n",
    "\n",
    "**Evaluated stats, currently**\n",
    "1. Total population between datasets\n",
    "2. Total urbanization\n",
    "3. 8-class SMOD breakdown\n",
    "4. Intersection of Water and GHSL\n",
    "5. Intersection of population and water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_res = []\n",
    "for iso3, data in all_res.groupby('ISO3'):\n",
    "    if iso3 in ['som','ken','ssd']:\n",
    "        pop_layers = list(data['pop_layer'].unique())\n",
    "        folder_base = os.path.dirname(os.path.dirname(data['Key'].iloc[0]))\n",
    "        iso3_res = []\n",
    "        tPrint(f\"Processing: {iso3}\")\n",
    "        for pop_layer in pop_layers:\n",
    "            orig_res = f's3://{bucket}/{folder_base}/{iso3}_{pop_layer}.tif'\n",
    "            res_250 = f's3://{bucket}/{folder_base}/FINAL_STANDARD/{iso3}_{pop_layer}.tif'\n",
    "            res_1000 = f's3://{bucket}/{folder_base}/FINAL_STANDARD_1KM/{iso3}1k_{pop_layer}.tif'\n",
    "            res = []\n",
    "            with rasterio.Env(GDAL_HTTP_UNSAFESSL=\"YES\"):\n",
    "                for c_res in [orig_res, res_250, res_1000]:                \n",
    "                    try:\n",
    "                        origR = rasterio.open(c_res)\n",
    "                        origD = origR.read(1)\n",
    "                        origD = np.where(origD > 0, origD, 0)\n",
    "                        res.append(origD.sum())\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error with {c_res}\")\n",
    "                        print(e)\n",
    "                        res.append(0)\n",
    "            pop_res.append([iso3, pop_layer, res[0], res[1], res[2]])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pop_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
