{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECA Urban extents\n",
    "\n",
    "Calculate urban extents using GHS-Pop for all of ECA; attribute with nighttime lights values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import multiprocessing\n",
    "import rasterio\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from botocore.config import Config\n",
    "from botocore import UNSIGNED\n",
    "from shapely.geometry import Point\n",
    "\n",
    "sys.path.insert(0, \"/home/wb411133/Code/gostrocks/src\")\n",
    "import GOSTRocks.rasterMisc as rMisc\n",
    "import GOSTRocks.ntlMisc as ntl\n",
    "from GOSTRocks.misc import tPrint\n",
    "\n",
    "sys.path.append(\"../../../src\")\n",
    "import GOST_Urban.country_helper as country_helper\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# read in local important parameters\n",
    "local_json = \"/home/wb411133/Code/urbanParameters.json\"\n",
    "with open(local_json, \"r\") as inJ:\n",
    "    important_vars = json.load(inJ)\n",
    "\n",
    "s3 = boto3.client(\"s3\", config=Config(signature_version=UNSIGNED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_population_ghs_file = \"/home/public/Data/GLOBAL/Population/GHS/2022_1km/GHS_POP_E2020_GLOBE_R2022A_54009_1000_V1_0.tif\"\n",
    "global_admin = \"/home/public/Data/GLOBAL/ADMIN/Admin0_Polys.shp\"\n",
    "global_ghsl_folder = \"/home/public/Data/GLOBAL/GHSL/v2022/\"\n",
    "\n",
    "output_folder = \"/home/wb411133/projects/KAZ_SCADR_Urbanization/DATA/ECA_Extents\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "ntl_files = ntl.aws_search_ntl()\n",
    "ghsl_files = [\n",
    "    os.path.join(global_ghsl_folder, x)\n",
    "    for x in os.listdir(global_ghsl_folder)\n",
    "    if x.endswith(\".tif\")\n",
    "]\n",
    "ghsl_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inR = rasterio.open(global_population_ghs_file)\n",
    "\n",
    "allAdmin = gpd.read_file(global_admin)\n",
    "inAdmin = allAdmin.loc[\n",
    "    (allAdmin[\"Region\"] == \"Europe & Central Asia\")\n",
    "    | (allAdmin[\"ISO3\"].isin([\"RUS\", \"ROU\", \"HRV\"]))\n",
    "]\n",
    "inAdmin = inAdmin.to_crs(inR.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate urban with helper object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_args = []\n",
    "for idx, row in inAdmin.iterrows():\n",
    "    iso3 = row[\"ISO3\"]\n",
    "    tPrint(f\"*********STARTING {iso3}\")\n",
    "    sel_country = gpd.GeoDataFrame(inAdmin.loc[inAdmin[\"ISO3\"] == iso3], crs=inR.crs)\n",
    "    sel_country[\"geometry\"] = sel_country[\"geometry\"].apply(lambda x: x.buffer(0))\n",
    "    cur_folder = os.path.join(output_folder, iso3)\n",
    "    if not os.path.exists(cur_folder):\n",
    "        os.makedirs(cur_folder)\n",
    "    pop_file = os.path.join(cur_folder, f\"{iso3}_ghs_pop_2020.tif\")\n",
    "    if not os.path.exists(pop_file):\n",
    "        rMisc.clipRaster(inR, sel_country, pop_file)\n",
    "    inP = rasterio.open(pop_file)\n",
    "    if iso3 == \"HRV\":\n",
    "        all_args.append(\n",
    "            [iso3, sel_country, cur_folder, pop_file, ntl_files, ghsl_files]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_extractor(iso3, sel_country, cur_folder, inP, ntl_files, ghsl_files):\n",
    "    extractor = country_helper.urban_country(iso3, sel_country, cur_folder, inP)\n",
    "    # extractor.delete_urban_data()\n",
    "    extractor.calculate_urban_extents()\n",
    "    extractor.summarize_ntl(ntl_files=ntl_files)\n",
    "    extractor.summarize_ghsl(ghsl_files, clip_raster=True, binary_calc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a single country\n",
    "run_extractor(*all_args[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with multiprocessing.Pool(len(all_args)) as pool:\n",
    "    pool.starmap(run_extractor, all_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_files = []\n",
    "center_files = []\n",
    "for root, folders, files in os.walk(output_folder):\n",
    "    for f in files:\n",
    "        if f.endswith(\"extents.geojson\"):\n",
    "            center_files.append(os.path.join(root, f))\n",
    "        if f.endswith(\"extents_hd.geojson\"):\n",
    "            hd_files.append(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res = []\n",
    "\n",
    "for cFile in center_files:\n",
    "    curD = gpd.read_file(cFile)\n",
    "    iso3 = os.path.basename(cFile)[:3]\n",
    "    curD[\"ISO3\"] = iso3\n",
    "    all_res.append(curD)\n",
    "\n",
    "final_center = pd.concat(all_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res = []\n",
    "\n",
    "for cFile in hd_files:\n",
    "    curD = gpd.read_file(cFile)\n",
    "    iso3 = os.path.basename(cFile)[:3]\n",
    "    curD[\"ISO3\"] = iso3\n",
    "    all_res.append(curD)\n",
    "\n",
    "hd_center = pd.concat(all_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match cities to centers\n",
    "inCities = pd.read_csv(\n",
    "    \"/home/wb411133/projects/KAZ_SCADR_Urbanization/DATA/CITIES/worldcities.csv\"\n",
    ")\n",
    "geoms = [Point(x) for x in zip(inCities[\"lng\"], inCities[\"lat\"])]\n",
    "inCities = gpd.GeoDataFrame(inCities, geometry=geoms, crs=4326)\n",
    "inCities.to_file(\n",
    "    \"/home/wb411133/projects/KAZ_SCADR_Urbanization/DATA/CITIES/worldcities.geojson\",\n",
    "    driver=\"GeoJSON\",\n",
    ")\n",
    "inCities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_center.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_center[\"wCity\"] = \"\"\n",
    "final_center.reset_index(inplace=True)\n",
    "\n",
    "for idx, row in final_center.iterrows():\n",
    "    try:\n",
    "        sel_city = inCities.loc[inCities.intersects(row[\"geometry\"])]\n",
    "    except:\n",
    "        sel_city = inCities.loc[inCities.intersects(row[\"geometry\"].buffer(0))]\n",
    "    if sel_city.shape[0] > 0:\n",
    "        final_center.loc[idx, \"wCity\"] = sel_city[\"city\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_center.to_file(\n",
    "    os.path.join(output_folder, \"all_urban_centers.geojson\"), driver=\"GeoJSON\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_center[\"wCity\"] = \"\"\n",
    "hd_center.reset_index(inplace=True)\n",
    "for idx, row in hd_center.iterrows():\n",
    "    try:\n",
    "        sel_city = inCities.loc[inCities.intersects(row[\"geometry\"])]\n",
    "    except:\n",
    "        sel_city = inCities.loc[inCities.intersects(row[\"geometry\"].buffer(0))]\n",
    "    if sel_city.shape[0] > 0:\n",
    "        hd_center.loc[idx, \"wCity\"] = sel_city[\"city\"].iloc[0]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_center.to_file(\n",
    "    os.path.join(output_folder, \"all_hd_urban_centers.geojson\"), driver=\"GeoJSON\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete GHSL files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_files = []\n",
    "for root, dirs, files in os.walk(output_folder):\n",
    "    for f in files:\n",
    "        if f.endswith(\"100_V1_0.tif\"):\n",
    "            bad_files.append(os.path.join(root, f))\n",
    "\n",
    "bad_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in bad_files:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
